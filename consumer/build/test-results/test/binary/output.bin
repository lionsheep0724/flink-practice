m14:43:12.516 [Test worker] INFO org.apache.kafka.clients.producer.ProducerConfig -- ProducerConfig values: 
	acks = -1
#	auto.include.jmx.reporter = true
	batch.size = 16384
(	bootstrap.servers = [127.0.0.1:53290]
	buffer.memory = 33554432
&	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
#	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
P	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
,	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
 	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
!	metrics.recording.level = INFO
#	metrics.sample.window.ms = 30000
2	partitioner.adaptive.partitioning.enable = true
*	partitioner.availability.timeout.ms = 0
	partitioner.class = null
"	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
"	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
,	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
+	sasl.kerberos.kinit.cmd = /usr/bin/kinit
0	sasl.kerberos.min.time.before.relogin = 60000
$	sasl.kerberos.service.name = null
+	sasl.kerberos.ticket.renew.jitter = 0.05
1	sasl.kerberos.ticket.renew.window.factor = 0.8
+	sasl.login.callback.handler.class = null
	sasl.login.class = null
'	sasl.login.connect.timeout.ms = null
$	sasl.login.read.timeout.ms = null
*	sasl.login.refresh.buffer.seconds = 300
-	sasl.login.refresh.min.period.seconds = 60
)	sasl.login.refresh.window.factor = 0.8
*	sasl.login.refresh.window.jitter = 0.05
*	sasl.login.retry.backoff.max.ms = 10000
$	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
+	sasl.oauthbearer.clock.skew.seconds = 30
,	sasl.oauthbearer.expected.audience = null
*	sasl.oauthbearer.expected.issuer = null
6	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
>	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
8	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
,	sasl.oauthbearer.jwks.endpoint.url = null
,	sasl.oauthbearer.scope.claim.name = scope
(	sasl.oauthbearer.sub.claim.name = sub
-	sasl.oauthbearer.token.endpoint.url = null
 	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
1	socket.connection.setup.timeout.max.ms = 30000
-	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
-	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
0	ssl.endpoint.identification.algorithm = https
"	ssl.engine.factory.class = null
	ssl.key.password = null
%	ssl.keymanager.algorithm = SunX509
(	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
*	ssl.secure.random.implementation = null
$	ssl.trustmanager.algorithm = PKIX
%	ssl.truststore.certificates = null
!	ssl.truststore.location = null
!	ssl.truststore.password = null
	ssl.truststore.type = JKS
!	transaction.timeout.ms = 60000
	transactional.id = null
U	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

ò14:43:12.523 [Test worker] INFO org.apache.kafka.clients.producer.KafkaProducer -- [Producer clientId=producer-1] Instantiated an idempotent producer.
e14:43:12.537 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka version: 3.4.1
q14:43:12.537 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka commitId: 8a516edc2755df89
q14:43:12.537 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka startTimeMs: 1741498992537
í14:43:12.549 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata -- [Producer clientId=producer-1] Resetting the last seen epoch of partition audio-packet-topic-0 to 0 since the associated topicId changed from null to kd5KX8qlQwS-Jq4ypIdZkQ
ß14:43:12.550 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata -- [Producer clientId=producer-1] Cluster ID: 1pLFQkF3RzqYfVPEOHkdow
È14:43:12.555 [controller-event-thread] INFO kafka.controller.KafkaController -- [Controller id=0] Acquired new producerId block ProducerIdsBlock(assignedBrokerId=0, firstProducerId=0, size=1000) by writing to Zk with path version 1
ª14:43:12.557 [Test worker] INFO org.apache.kafka.clients.producer.KafkaProducer -- [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
¬14:43:12.557 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.producer.internals.TransactionManager -- [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
e14:43:12.589 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics scheduler closed
â14:43:12.589 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Closing reporter org.apache.kafka.common.metrics.JmxReporter
e14:43:12.589 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics reporters closed
Ñ14:43:12.589 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- App info kafka.producer for producer-1 unregistered
m14:43:12.593 [Test worker] INFO org.apache.kafka.clients.consumer.ConsumerConfig -- ConsumerConfig values: 
"	allow.auto.create.topics = true
!	auto.commit.interval.ms = 5000
#	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
(	bootstrap.servers = [127.0.0.1:53290]
	check.crcs = true
&	client.dns.lookup = use_all_dns_ips
$	client.id = consumer-test-group-1
	client.rack = 
#	connections.max.idle.ms = 540000
!	default.api.timeout.ms = 60000
	enable.auto.commit = true
!	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
'	internal.leave.group.on.close = true
<	internal.throw.on.fetch.stable.offset.unsupported = false
%	isolation.level = read_uncommitted
T	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
&	max.partition.fetch.bytes = 1048576
 	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
!	metrics.recording.level = INFO
#	metrics.sample.window.ms = 30000
ù	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
"	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
,	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
+	sasl.kerberos.kinit.cmd = /usr/bin/kinit
0	sasl.kerberos.min.time.before.relogin = 60000
$	sasl.kerberos.service.name = null
+	sasl.kerberos.ticket.renew.jitter = 0.05
1	sasl.kerberos.ticket.renew.window.factor = 0.8
+	sasl.login.callback.handler.class = null
	sasl.login.class = null
'	sasl.login.connect.timeout.ms = null
$	sasl.login.read.timeout.ms = null
*	sasl.login.refresh.buffer.seconds = 300
-	sasl.login.refresh.min.period.seconds = 60
)	sasl.login.refresh.window.factor = 0.8
*	sasl.login.refresh.window.jitter = 0.05
*	sasl.login.retry.backoff.max.ms = 10000
$	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
+	sasl.oauthbearer.clock.skew.seconds = 30
,	sasl.oauthbearer.expected.audience = null
*	sasl.oauthbearer.expected.issuer = null
6	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
>	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
8	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
,	sasl.oauthbearer.jwks.endpoint.url = null
,	sasl.oauthbearer.scope.claim.name = scope
(	sasl.oauthbearer.sub.claim.name = sub
-	sasl.oauthbearer.token.endpoint.url = null
 	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
1	socket.connection.setup.timeout.max.ms = 30000
-	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
-	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
0	ssl.endpoint.identification.algorithm = https
"	ssl.engine.factory.class = null
	ssl.key.password = null
%	ssl.keymanager.algorithm = SunX509
(	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
*	ssl.secure.random.implementation = null
$	ssl.trustmanager.algorithm = PKIX
%	ssl.truststore.certificates = null
!	ssl.truststore.location = null
!	ssl.truststore.password = null
	ssl.truststore.type = JKS
Y	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

e14:43:12.619 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka version: 3.4.1
q14:43:12.619 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka commitId: 8a516edc2755df89
q14:43:12.619 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka startTimeMs: 1741498992619
Ω14:43:12.619 [Test worker] INFO org.apache.kafka.clients.consumer.KafkaConsumer -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Subscribed to topic(s): audio-packet-topic
í14:43:12.623 [Test worker] INFO org.apache.kafka.clients.Metadata -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Resetting the last seen epoch of partition audio-packet-topic-0 to 0 since the associated topicId changed from null to kd5KX8qlQwS-Jq4ypIdZkQ
ß14:43:12.623 [Test worker] INFO org.apache.kafka.clients.Metadata -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Cluster ID: 1pLFQkF3RzqYfVPEOHkdow
Ê14:43:12.626 [data-plane-kafka-request-handler-0] INFO kafka.zk.AdminZkClient -- Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
Ë14:43:12.631 [controller-event-thread] INFO kafka.controller.KafkaController -- [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(DqjOd3diRfKyi3--Nwphig),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
14:43:12.631 [controller-event-thread] INFO kafka.controller.KafkaController -- [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
Œ14:43:12.631 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
Œ14:43:12.631 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
Œ14:43:12.631 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
Œ14:43:12.631 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
Œ14:43:12.631 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
£14:43:12.631 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
£14:43:12.631 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
ô14:43:12.635 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
ô14:43:12.636 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
ô14:43:12.636 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
ô14:43:12.636 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
ô14:43:12.636 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
Ω14:43:12.636 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
§14:43:12.636 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
£14:43:12.636 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
Æ14:43:12.636 [data-plane-kafka-request-handler-2] INFO state.change.logger -- [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
ó14:43:12.639 [data-plane-kafka-request-handler-2] INFO kafka.server.ReplicaFetcherManager -- [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
Ò14:43:12.639 [data-plane-kafka-request-handler-2] INFO state.change.logger -- [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
™14:43:12.650 [data-plane-kafka-request-handler-2] INFO kafka.log.UnifiedLog$ -- [LogLoader partition=__consumer_offsets-3, dir=C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896] Loading producer state till offset 0 with message format version 2
‹14:43:12.650 [data-plane-kafka-request-handler-2] INFO kafka.log.LogManager -- Created log for partition __consumer_offsets-3 in C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
«14:43:12.651 [data-plane-kafka-request-handler-2] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
…14:43:12.651 [data-plane-kafka-request-handler-2] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
…14:43:12.651 [data-plane-kafka-request-handler-2] INFO state.change.logger -- [Broker id=0] Leader __consumer_offsets-3 with topic id Some(DqjOd3diRfKyi3--Nwphig) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
™14:43:12.661 [data-plane-kafka-request-handler-2] INFO kafka.log.UnifiedLog$ -- [LogLoader partition=__consumer_offsets-2, dir=C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896] Loading producer state till offset 0 with message format version 2
‹14:43:12.662 [data-plane-kafka-request-handler-2] INFO kafka.log.LogManager -- Created log for partition __consumer_offsets-2 in C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
«14:43:12.662 [data-plane-kafka-request-handler-2] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
…14:43:12.662 [data-plane-kafka-request-handler-2] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
…14:43:12.662 [data-plane-kafka-request-handler-2] INFO state.change.logger -- [Broker id=0] Leader __consumer_offsets-2 with topic id Some(DqjOd3diRfKyi3--Nwphig) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
™14:43:12.673 [data-plane-kafka-request-handler-2] INFO kafka.log.UnifiedLog$ -- [LogLoader partition=__consumer_offsets-4, dir=C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896] Loading producer state till offset 0 with message format version 2
‹14:43:12.673 [data-plane-kafka-request-handler-2] INFO kafka.log.LogManager -- Created log for partition __consumer_offsets-4 in C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
«14:43:12.673 [data-plane-kafka-request-handler-2] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
…14:43:12.673 [data-plane-kafka-request-handler-2] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
…14:43:12.673 [data-plane-kafka-request-handler-2] INFO state.change.logger -- [Broker id=0] Leader __consumer_offsets-4 with topic id Some(DqjOd3diRfKyi3--Nwphig) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
™14:43:12.684 [data-plane-kafka-request-handler-2] INFO kafka.log.UnifiedLog$ -- [LogLoader partition=__consumer_offsets-1, dir=C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896] Loading producer state till offset 0 with message format version 2
‹14:43:12.684 [data-plane-kafka-request-handler-2] INFO kafka.log.LogManager -- Created log for partition __consumer_offsets-1 in C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
«14:43:12.684 [data-plane-kafka-request-handler-2] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
…14:43:12.684 [data-plane-kafka-request-handler-2] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
…14:43:12.684 [data-plane-kafka-request-handler-2] INFO state.change.logger -- [Broker id=0] Leader __consumer_offsets-1 with topic id Some(DqjOd3diRfKyi3--Nwphig) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
™14:43:12.697 [data-plane-kafka-request-handler-2] INFO kafka.log.UnifiedLog$ -- [LogLoader partition=__consumer_offsets-0, dir=C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896] Loading producer state till offset 0 with message format version 2
‹14:43:12.697 [data-plane-kafka-request-handler-2] INFO kafka.log.LogManager -- Created log for partition __consumer_offsets-0 in C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
«14:43:12.697 [data-plane-kafka-request-handler-2] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
…14:43:12.697 [data-plane-kafka-request-handler-2] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
…14:43:12.697 [data-plane-kafka-request-handler-2] INFO state.change.logger -- [Broker id=0] Leader __consumer_offsets-0 with topic id Some(DqjOd3diRfKyi3--Nwphig) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
∂14:43:12.704 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
·14:43:12.705 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
∂14:43:12.705 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
·14:43:12.705 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
∂14:43:12.705 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
·14:43:12.706 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
∂14:43:12.706 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
·14:43:12.706 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
∂14:43:12.706 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
·14:43:12.706 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
∂14:43:12.706 [data-plane-kafka-request-handler-2] INFO state.change.logger -- [Broker id=0] Finished LeaderAndIsr request in 70ms correlationId 3 from controller 0 for 5 partitions
Ù14:43:12.707 [data-plane-kafka-request-handler-3] INFO state.change.logger -- [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
ô14:43:12.709 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
ô14:43:12.709 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
ô14:43:12.709 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler.
ô14:43:12.709 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler.
ô14:43:12.709 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler.
Î14:43:12.727 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Discovered group coordinator localhost:53290 (id: 2147483647 rack: null)
µ14:43:12.729 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] (Re-)joining group
…14:43:12.741 [data-plane-kafka-request-handler-7] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Dynamic member with unknown member id joins group test-group in Empty state. Created a new member id consumer-test-group-1-b874b22d-efcf-418d-b478-9755978bc68a and request the member to rejoin with this id.
•14:43:12.744 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-1-b874b22d-efcf-418d-b478-9755978bc68a
“14:43:12.745 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
µ14:43:12.745 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] (Re-)joining group
†14:43:12.747 [data-plane-kafka-request-handler-0] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-test-group-1-b874b22d-efcf-418d-b478-9755978bc68a with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
π14:43:12.752 [executor-Rebalance] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Stabilized group test-group generation 1 (__consumer_offsets-2) with 1 members
¿14:43:12.753 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-1-b874b22d-efcf-418d-b478-9755978bc68a', protocol='range'}
º14:43:12.754 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Finished assignment for group at generation 1: {consumer-test-group-1-b874b22d-efcf-418d-b478-9755978bc68a=Assignment(partitions=[audio-packet-topic-0])}
¨14:43:12.761 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Assignment received from leader consumer-test-group-1-b874b22d-efcf-418d-b478-9755978bc68a for group test-group for generation 1. The group has 1 members, 0 of which are static.
æ14:43:12.768 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-1-b874b22d-efcf-418d-b478-9755978bc68a', protocol='range'}
Ò14:43:12.768 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Notifying assignor about the new Assignment(partitions=[audio-packet-topic-0])
Ÿ14:43:12.770 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Adding newly assigned partitions: audio-packet-topic-0
ﬂ14:43:12.775 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Found no committed offset for partition audio-packet-topic-0
Ò14:43:12.783 [Test worker] INFO org.apache.kafka.clients.consumer.internals.SubscriptionState -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Resetting offset for partition audio-packet-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:53290 (id: 0 rack: null)], epoch=0}}.
›14:43:12.816 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Revoke previously assigned partitions audio-packet-topic-0
ﬁ14:43:12.816 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Member consumer-test-group-1-b874b22d-efcf-418d-b478-9755978bc68a sending LeaveGroup request to coordinator localhost:53290 (id: 2147483647 rack: null) due to the consumer is being closed
ı14:43:12.816 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
Ë14:43:12.816 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
˚14:43:12.819 [data-plane-kafka-request-handler-7] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-test-group-1-b874b22d-efcf-418d-b478-9755978bc68a on LeaveGroup; client reason: the consumer is being closed)
¡14:43:12.819 [data-plane-kafka-request-handler-7] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Group test-group with generation 2 is now empty (__consumer_offsets-2)
Ó14:43:12.820 [data-plane-kafka-request-handler-7] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-test-group-1-b874b22d-efcf-418d-b478-9755978bc68a, groupInstanceId=None, clientId=consumer-test-group-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group test-group through explicit `LeaveGroup`; client reason: the consumer is being closed
e14:43:12.821 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics scheduler closed
â14:43:12.822 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Closing reporter org.apache.kafka.common.metrics.JmxReporter
e14:43:12.822 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics reporters closed
è14:43:12.822 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- App info kafka.consumer for consumer-test-group-1 unregistered
@Consumed record: key = test-session, value length = 5120 bytes
NFirst 20 bytes: 27 A3 7B 0E 1B D4 DC 3C 4D A2 2B 84 5F F7 D2 C2 2D A8 CE D4 
 ^14:43:12.828 [Test worker] INFO kafka.server.KafkaServer -- [KafkaServer id=0] shutting down
 °14:43:12.829 [Test worker] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread -- [/config/changes-event-process-thread]: Shutting down
 ¶14:43:12.829 [Test worker] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread -- [/config/changes-event-process-thread]: Shutdown completed
 ¥14:43:12.829 [/config/changes-event-process-thread] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread -- [/config/changes-event-process-thread]: Stopped
 ô14:43:12.829 [Test worker] INFO kafka.network.SocketServer -- [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
  14:43:12.831 [BrokerToControllerChannelManager broker=0 name=forwarding] INFO org.apache.kafka.clients.NetworkClient -- [BrokerToControllerChannelManager broker=0 name=forwarding] Node 0 disconnected.
 ò14:43:12.832 [Test worker] INFO kafka.network.SocketServer -- [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
 á14:43:12.833 [Test worker] INFO kafka.server.KafkaRequestHandlerPool -- [data-plane Kafka Request Handler on Broker 0], shutting down
 é14:43:12.834 [Test worker] INFO kafka.server.KafkaRequestHandlerPool -- [data-plane Kafka Request Handler on Broker 0], shut down completely
 ê14:43:12.835 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-AlterAcls]: Shutting down
 õ14:43:12.836 [ExpirationReaper-0-AlterAcls] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-AlterAcls]: Stopped
 ï14:43:12.836 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-AlterAcls]: Shutdown completed
 [14:43:12.836 [Test worker] INFO kafka.server.KafkaApis -- [KafkaApi-0] Shutdown complete.
 å14:43:12.837 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-topic]: Shutting down
 ì14:43:12.837 [ExpirationReaper-0-topic] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-topic]: Stopped
 ë14:43:12.837 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-topic]: Shutdown completed
 Ü14:43:12.838 [Test worker] INFO kafka.coordinator.transaction.TransactionCoordinator -- [TransactionCoordinator id=0] Shutting down.
 ã14:43:12.839 [Test worker] INFO kafka.coordinator.transaction.TransactionStateManager -- [Transaction State Manager 0]: Shutdown complete
 ò14:43:12.839 [Test worker] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager -- [Transaction Marker Channel Manager 0]: Shutting down
 û14:43:12.839 [TxnMarkerSenderThread-0] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager -- [Transaction Marker Channel Manager 0]: Stopped
 ù14:43:12.839 [Test worker] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager -- [Transaction Marker Channel Manager 0]: Shutdown completed
 ä14:43:12.840 [Test worker] INFO kafka.coordinator.transaction.TransactionCoordinator -- [TransactionCoordinator id=0] Shutdown complete.
 r14:43:12.840 [Test worker] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Shutting down.
 ê14:43:12.840 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Heartbeat]: Shutting down
 õ14:43:12.840 [ExpirationReaper-0-Heartbeat] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Heartbeat]: Stopped
 ï14:43:12.840 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Heartbeat]: Shutdown completed
 ê14:43:12.840 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Rebalance]: Shutting down
 õ14:43:12.840 [ExpirationReaper-0-Rebalance] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Rebalance]: Stopped
 ï14:43:12.840 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Rebalance]: Shutdown completed
 v14:43:12.841 [Test worker] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Shutdown complete.
 h14:43:12.841 [Test worker] INFO kafka.server.ReplicaManager -- [ReplicaManager broker=0] Shutting down
 {14:43:12.841 [Test worker] INFO kafka.server.ReplicaManager$LogDirFailureHandler -- [LogDirFailureHandler]: Shutting down
 Ä14:43:12.841 [Test worker] INFO kafka.server.ReplicaManager$LogDirFailureHandler -- [LogDirFailureHandler]: Shutdown completed
 ~14:43:12.841 [LogDirFailureHandler] INFO kafka.server.ReplicaManager$LogDirFailureHandler -- [LogDirFailureHandler]: Stopped
 y14:43:12.841 [Test worker] INFO kafka.server.ReplicaFetcherManager -- [ReplicaFetcherManager on broker 0] shutting down
 ~14:43:12.842 [Test worker] INFO kafka.server.ReplicaFetcherManager -- [ReplicaFetcherManager on broker 0] shutdown completed
 É14:43:12.842 [Test worker] INFO kafka.server.ReplicaAlterLogDirsManager -- [ReplicaAlterLogDirsManager on broker 0] shutting down
 à14:43:12.842 [Test worker] INFO kafka.server.ReplicaAlterLogDirsManager -- [ReplicaAlterLogDirsManager on broker 0] shutdown completed
 å14:43:12.842 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Fetch]: Shutting down
 ë14:43:12.842 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Fetch]: Shutdown completed
 ì14:43:12.842 [ExpirationReaper-0-Fetch] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Fetch]: Stopped
 é14:43:12.842 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Produce]: Shutting down
 ó14:43:12.842 [ExpirationReaper-0-Produce] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Produce]: Stopped
 ì14:43:12.842 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Produce]: Shutdown completed
 î14:43:12.843 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-DeleteRecords]: Shutting down
 £14:43:12.843 [ExpirationReaper-0-DeleteRecords] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-DeleteRecords]: Stopped
 ô14:43:12.843 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-DeleteRecords]: Shutdown completed
 í14:43:12.843 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-ElectLeader]: Shutting down
 ó14:43:12.843 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-ElectLeader]: Shutdown completed
 ü14:43:12.843 [ExpirationReaper-0-ElectLeader] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-ElectLeader]: Stopped
 o14:43:12.849 [Test worker] INFO kafka.server.ReplicaManager -- [ReplicaManager broker=0] Shut down completely
 †14:43:12.849 [Test worker] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
 •14:43:12.849 [Test worker] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
 Ã14:43:12.849 [BrokerToControllerChannelManager broker=0 name=alterPartition] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
 ó14:43:12.850 [Test worker] INFO kafka.server.BrokerToControllerChannelManagerImpl -- Broker to controller channel manager for alterPartition shutdown
 ú14:43:12.850 [Test worker] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
 ƒ14:43:12.850 [BrokerToControllerChannelManager broker=0 name=forwarding] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
 °14:43:12.850 [Test worker] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
 ì14:43:12.850 [Test worker] INFO kafka.server.BrokerToControllerChannelManagerImpl -- Broker to controller channel manager for forwarding shutdown
 H14:43:12.850 [Test worker] INFO kafka.log.LogManager -- Shutting down.
 X14:43:12.851 [Test worker] INFO kafka.log.LogCleaner -- Shutting down the log cleaner.
 e14:43:12.851 [Test worker] INFO kafka.log.LogCleaner -- [kafka-log-cleaner-thread-0]: Shutting down
 n14:43:12.851 [kafka-log-cleaner-thread-0] INFO kafka.log.LogCleaner -- [kafka-log-cleaner-thread-0]: Stopped
 j14:43:12.851 [Test worker] INFO kafka.log.LogCleaner -- [kafka-log-cleaner-thread-0]: Shutdown completed
 †14:43:12.889 [log-closing-C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896] INFO kafka.log.ProducerStateManager -- [ProducerStateManager partition=audio-packet-topic-0] Wrote producer snapshot at offset 1 with 1 producer ids in 5 ms.
 †14:43:12.899 [log-closing-C:\Users\user\AppData\Local\Temp\spring.kafka.98259f4e-7e6f-4f18-8efa-59eac2f040681183013352309797896] INFO kafka.log.ProducerStateManager -- [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 3 with 0 producer ids in 4 ms.
 L14:43:12.914 [Test worker] INFO kafka.log.LogManager -- Shutdown complete.
 ó14:43:12.914 [Test worker] INFO kafka.controller.ControllerEventManager$ControllerEventThread -- [ControllerEventThread controllerId=0] Shutting down
 ú14:43:12.914 [Test worker] INFO kafka.controller.ControllerEventManager$ControllerEventThread -- [ControllerEventThread controllerId=0] Shutdown completed
 ù14:43:12.914 [controller-event-thread] INFO kafka.controller.ControllerEventManager$ControllerEventThread -- [ControllerEventThread controllerId=0] Stopped
 î14:43:12.915 [Test worker] INFO kafka.controller.ZkPartitionStateMachine -- [PartitionStateMachine controllerId=0] Stopped partition state machine
 é14:43:12.916 [Test worker] INFO kafka.controller.ZkReplicaStateMachine -- [ReplicaStateMachine controllerId=0] Stopped replica state machine
 x14:43:12.916 [Test worker] INFO kafka.controller.RequestSendThread -- [RequestSendThread controllerId=0] Shutting down
 ã14:43:12.916 [Controller-0-to-broker-0-send-thread] INFO kafka.controller.RequestSendThread -- [RequestSendThread controllerId=0] Stopped
 }14:43:12.916 [Test worker] INFO kafka.controller.RequestSendThread -- [RequestSendThread controllerId=0] Shutdown completed
 `14:43:12.916 [Test worker] INFO kafka.controller.KafkaController -- [Controller id=0] Resigned
 ®14:43:12.916 [Test worker] INFO kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread -- [feature-zk-node-event-process-thread]: Shutting down
 ª14:43:12.916 [feature-zk-node-event-process-thread] INFO kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread -- [feature-zk-node-event-process-thread]: Stopped
 ≠14:43:12.916 [Test worker] INFO kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread -- [feature-zk-node-event-process-thread]: Shutdown completed
 l14:43:12.917 [Test worker] INFO kafka.zookeeper.ZooKeeperClient -- [ZooKeeperClient Kafka server] Closing.
 e14:43:13.019 [Test worker] INFO org.apache.zookeeper.ZooKeeper -- Session: 0x1002c6b878b0000 closed
 Ö14:43:13.019 [Test worker-EventThread] INFO org.apache.zookeeper.ClientCnxn -- EventThread shut down for session: 0x1002c6b878b0000
 k14:43:13.020 [Test worker] INFO kafka.zookeeper.ZooKeeperClient -- [ZooKeeperClient Kafka server] Closed.
 â14:43:13.020 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Fetch]: Shutting down
 î14:43:13.021 [ThrottledChannelReaper-Fetch] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Fetch]: Stopped
 é14:43:13.021 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Fetch]: Shutdown completed
 ã14:43:13.021 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Produce]: Shutting down
 ò14:43:13.021 [ThrottledChannelReaper-Produce] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Produce]: Stopped
 ê14:43:13.021 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Produce]: Shutdown completed
 ã14:43:13.021 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Request]: Shutting down
 ò14:43:13.021 [ThrottledChannelReaper-Request] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Request]: Stopped
 ê14:43:13.021 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Request]: Shutdown completed
 ñ14:43:13.021 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-ControllerMutation]: Shutting down
 Æ14:43:13.021 [ThrottledChannelReaper-ControllerMutation] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-ControllerMutation]: Stopped
 õ14:43:13.021 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
 ã14:43:13.022 [Test worker] INFO kafka.network.SocketServer -- [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
 Ç14:43:13.028 [Test worker] INFO kafka.network.SocketServer -- [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
 e14:43:13.029 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics scheduler closed
 â14:43:13.029 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Closing reporter org.apache.kafka.common.metrics.JmxReporter
 e14:43:13.029 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics reporters closed
 `14:43:13.029 [Test worker] INFO kafka.server.BrokerTopicStats -- Broker and topic stats closed
 y14:43:13.030 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- App info kafka.server for 0 unregistered
 d14:43:13.030 [Test worker] INFO kafka.server.KafkaServer -- [KafkaServer id=0] shut down completed
 Å14:43:13.039 [ConnnectionExpirer] INFO org.apache.zookeeper.server.NIOServerCnxnFactory -- ConnnectionExpirerThread interrupted
 ò14:43:13.039 [NIOServerCxnFactory.AcceptThread:/127.0.0.1:0] INFO org.apache.zookeeper.server.NIOServerCnxnFactory -- accept thread exitted run method
 ë14:43:13.039 [NIOServerCxnFactory.SelectorThread-0] INFO org.apache.zookeeper.server.NIOServerCnxnFactory -- selector thread exitted run method
 ë14:43:13.039 [NIOServerCxnFactory.SelectorThread-1] INFO org.apache.zookeeper.server.NIOServerCnxnFactory -- selector thread exitted run method
 ë14:43:13.040 [NIOServerCxnFactory.SelectorThread-2] INFO org.apache.zookeeper.server.NIOServerCnxnFactory -- selector thread exitted run method
 ^14:43:13.040 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer -- shutting down
 _14:43:13.040 [Test worker] INFO org.apache.zookeeper.server.RequestThrottler -- Shutting down
 w14:43:13.040 [RequestThrottler] INFO org.apache.zookeeper.server.RequestThrottler -- Draining request throttler queue
 Ñ14:43:13.040 [RequestThrottler] INFO org.apache.zookeeper.server.RequestThrottler -- RequestThrottler shutdown. Dropped 0 requests
 a14:43:13.040 [Test worker] INFO org.apache.zookeeper.server.SessionTrackerImpl -- Shutting down
 c14:43:13.040 [Test worker] INFO org.apache.zookeeper.server.PrepRequestProcessor -- Shutting down
 c14:43:13.040 [Test worker] INFO org.apache.zookeeper.server.SyncRequestProcessor -- Shutting down
 ç14:43:13.040 [ProcessThread(sid:0 cport:53286):] INFO org.apache.zookeeper.server.PrepRequestProcessor -- PrepRequestProcessor exited loop!
 s14:43:13.040 [SyncThread:0] INFO org.apache.zookeeper.server.SyncRequestProcessor -- SyncRequestProcessor exited!
 }14:43:13.040 [Test worker] INFO org.apache.zookeeper.server.FinalRequestProcessor -- shutdown of request processor complete
Sending request for chunk 1
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
æ    "data": ["+3SkH25nzkugpTcBcIJTbgBs/pnkXK/L39TU/Iv6jwGgxsMf/I67FZsIUzuz1x2gSrLTdIqj8veBrPuBk+qN1QOf1S21ZEi9MW/tEHsqNx+u6F4F7epwRyFXq1F2chfGjFDzMBzy8CrCwY0amntaiAUL1XEbzsFs4LAhrqGopQSoZaHhZ7Lb4U4KZde4dhzEb0kDDxRB8NbBrZRRl6f6ekcdlSMBlcps/IQr5tF43g/QzJ+FTDtpSy3y/5NsfK4wYff8vgjQOfaWQF+JtOarhk6LPrItMiUecPvchkxl++JsUZ4gz4KW9QtPhkuF0/s+1SxcypNjlmY52IdD8l9j+egSWqBdKLdu7YVWyjv3kPeT/zBtTvAlFx5xUr8xCAn71Gnqbe3Z//vxzuTpI/Xxmnz8PaujxkkMFmGIFm/G1Yk1l+urbGHcvnEIPvNb8jOWx9vFu8tcff/9XeVlJU7HsZbLgXH+G3pd7XULbFh8ER1uOaQLczunyRMxQPhgbP4LgxMuY3qs62eFwCTHYL+H+rLJNI07WLWHfT9sxEMmac4NVKRT6X0g2oGHMWgRDXR6lp08tTdAegPDopP1gyciYklXtOULFlrzyoC81tiy601fdwddcRIVOlDRi37pgN+D0eiXeNI3CUduKVpneyBICRovK9ZkSm749tbmhtS2CkNBAjjA5NU8vh8GxROQXiEAFiej2INak01nHcPWtB9cbbsHO0sd1Qw8tXMRtQPVsNBl0DWYsBb7Ab3Em0SQkhMWZBTu4AufqrqoB1tVlGFW5WA/VjrF7vxZ84ubjoFlKPHkVlsRcIQBApaAjdhWvjmQINDzGQ/5BClpSTT3NbwKLOp9H4rE7xCMw0YrzjI4QioG2+nCzcxOomTz/HJtJtBGpjTQwrFnasaUfDPYYrXeyzN5AVO1LDFjizgYNH+O5TFNrwVclWF9oxOfibX2C1jLEFm3+nCBROprqKXl1HegnZlHWRwD5JpZbraAqFKopynIojesGiTuDfRr//drjUn6RinrzkL52kB4FmykroMMfMnsQaPDeBoM+43G9FWAeiCWDkFnzPFN/CevV2eVatitR0DnVPDYL3y20//vNzbp+s4MkLbRdiN+FO1JZ2eTLyu5LVSCGk6Ew0Mlw9HLR/rTt3DDrrJssQH+KbFE14S0olrxGJ4tHOCrIYY/Yl/PtBoeq9KnhqWEyUet3kVtTFqRqaehbwsc12K0nRW4VIfxi1RNOFyYY+VKdTyxOQQF1zjpkdDkB+YCeMXPSuegON+trhWcWeareXOzO9EBTa1wdqJq7E1rzGdnAOVWlU15NnUGDAJzpGjv4E1eIO9LTh4tHspU1PKljtx1Qw5l97q2vDiuEFq3W9g1N+c+DdVxN5vtmq7YTmgdIhi3agNSqcbwpixA5TvhITKHeUh0GOkrAWGeegmjkvggQcp0/KLYUfK1tgSx/oHS2Pd4KroS4/1zEwFIbwpoN+ktrs9lQsQ9vU7XRboCVve3ZPo1pxhTeJNc//RfD/p0/nuzqdoeHRDQXuG0SP8261pRRM9jUadbId2Zr0Y0A0iIr1ITOzhooKtWbNT/3sJhCmXfXG84z/oj+FmocmyR6xayxP4eJu3uAqvgwjU/LuBA6DbY0h2SAlRUJqmqoIBi41AravOS9HpcVxQav/TmjaVKyaErpTVlEl0nAhguxZ9RuUl2RrlWsvc="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": true,
    "sequence_end": false,
!    "sequence_id": 1741498993140
  }
}
ŸReceived response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Response JSON for chunk 1:
∆{"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Sending request for chunk 2
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
æ    "data": ["Vvd1N4QGh/Kd6HpdRnSkCMG7fjdkhn0CAM1r3e1ZVMIqUHRuqZQa5xYLx/TMw/Pi9HxU4wkJjfKfJPHNE+HhCliIPwnSmZ5JkKt2hNfr7EitUz411WkJ+vHq8vkm6nRm6Yj2mKIBxAcIuj2VWuzQVmecNfT1J3eBt90A/LJcmfHqpoNeb02UtyKc9w0eNI9e4Vt7fYh/umWUZiHIWSgBreyftLTEFoMWo71aVz0nDaWeg+OcJJSu1ZGzXQNSsy04hKalod9hPaf1sF3fp/VnJWZGlJRRa4dqmV+IWuWYaJXMftFgM8AgOqbf7wqgwSohw3yrqAy3iNv+qgDv8Lel8+CqWM/nQoT/6crnFkAWs2mFGXzfRnDbdPJDdEZlkSi0YqdRhFY9Pb4T3Ejj8q093D+uVUtjQYzoD5/hCMn2BgP3NzQHjdcJ7B/FQib1iFV/x/8HH7zA/CfQ31w+twjjYsjDsQbRcMuwK3GMDt5Tnw26qpQCHXtRsxZRWaxbhXZ9AsKMqhbSulD5hPzuFB47f/XXwJlHzqYzo215aPhmyWNWNkEbiDAAFW9vgSdTYDZQHQF58m+TFkSieCe1Y9ItKno9kCIGAFmNFwrbISpTyNcYxTidvZnYBB2meMKFVVt1palAWKKVtfCfybfifZVSAZLM6IXP8AdzhtMc/Nx1Qx8Xr6amIpr4dVp+F2IDI2Adeb7kPzMD14Yv0Fwj+o55k4+gxBKCTEK5vqQVmMiaHE6CRBtc8IA8ydE1aZIFAUjk07sWnHCUcaXkRX3trdX9R6Ifeoz+GWNpCdF7rDavzOIsBly4z+TE5AxoyInjzJm8lUwYzMkIZtnWmY2sWs62tec47mc17sSOFg9tynTQ4spaONB/smwkoR08o7pUA4CD1b16H2wh46QJzZkJug1EPbQEPIeOdDVlJTDybZnROsbLuy7M9AF28pDiw7zmZVgzq9xFgiVZRxcbY2CosllQyCMzqAeASP0Pd++o3XqUNRIJWb4jtCdz5JBvIAa9Z8eaOio+KXXV15wzM6aCz6WFO970qkVsXE+99mVs8u3R7o7w6XFCbnPVPVhdh4WQvegY/ZE+mPBMy0ImJaHQBieF3itKmzy6aU6SIO4uGj0tWX58Da4w22IdetxCPI/irLe2VA4iPtzeqhzrJrpAqtqLQzjkUvE4Jk7pOYR+aO6ukkvYUdY1CguEDrmKAhF99oY5TufNwAgYKqVB5rSKrRy98qgEOuuvOskDsu6e97MC6U6jABzKwFykaFs2auA0eJmFuXfNOuqgkvueGsYeGymayl4Hz4vINvQE1DoDN6wUJnSF+bA1DfqLSG35tGfZ4eEBaaTcUP1Q91hca4eQ1KQ2A4mCLbQe/iDGsVl6i+XpGtTzRrXJL9mihYc5mIN9GeEpxXH2ilmj1VofPko0iol/g/AoleCkao1ETenYKgzQN2M/WTb7rDB0sxK+uiLnKsg3l2NBkJPI2xyK+UhL+xCrkoDauCU5IPstCHaMvHFAlpTjE6N4qmgasn8cUwdX3qvKFZPDQdjRdB4jiOC0b3vlUhOP8iiJzc2PT8CSqkMSal4PGXAYkg0j86gs/td9Uv25K6dkm0Wxw6ODJ5LYdc3HKIMHmc0nVqhAg9IJZwrYnClx/4sq5v9uEIYRA6+0NdxbCxusT4kLGWrCz0/a2eBapPBw4FzoodgfKvMzOmCEn30="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": false,
    "sequence_end": false,
!    "sequence_id": 1741498993140
  }
}
‘Received response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["NOSPEECH"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Response JSON for chunk 2:
¡{"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["NOSPEECH"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Sending request for chunk 3
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
æ    "data": ["RF7z319dHmwWogRThHp0bvh+Hj++Fu/mIr/D8Opkmm9OZicFgw2VTVW/nH/0sYNinNtwqkrfPpiGPtbJV6OygE+fXOKEAlLb+vUdOOqp2JIy/JW/Z7hdnFL5SufBKm+R8KidXCWq9p+jXQyiegFvK9e9cxRgpZJF5q64u9ZTTUTewsSx3Cv/e5LX1D2LirlN6RnLjXXKhFuHXi8KV4MBDUpJZiNUa3TdLh/X2VhQvsyL6v2iXRf7yt3fAhyaGL2yakHeIOva61l/anEJ8e08RSS/GNa/wfZ8cwsgDwms04L29dLrNR6/WLWar2i7NNkK4MCSfriPsrc7c64toZ1ZAqujvgp3fKWOofx/p+wihMgtp3WhWPJQcwerANZ085VmzDVS/SwjGUc5mY8RECqdf0C833Uk8EK7ESEVmCeIYX2cEsOOhDgy2xkWMAqHxYXGjvERYZbfsYx0hinUdYnN9+X3VdLgveFA/SXpvQRhocRTBHypmPF1obDHIlSqRqs6dOe4TldCtlBIiZcdD4/7bg6yeNwNjGM+KpXLDyhPz/GaI/4cNWWUO4GeOxGEjw72A/2r5kl0+WqpeyuK5eAppK07Ssh2KA2t0ILZshImZCq4gDUrk8m579qMePzrpg5whSiHi08TPEKFwgxMvsAK23jWKHqqz7cXzpdl0djHRej/eK4ipiRXUJKZMcNd7hjW0wn+oj2JJHl38c7JW0TAw32OfMWVlVpxDMRFHx0luUAcHeyDciLk9y7NB4K9pQmzZemeCetrevCu3uLL/Nh3ceqdX+NgK3bMMCVK9VX80Deeha9aqtxD+1VX9FBP4s1Ul0n/FJSiupgcMwsLEy4jzBZHj26Kfphvhe0KRD00IanEwfBnkM9de3d4NjD2lDAAPnbxnHVM7Tniwm9TQuO1DNNQT6BH7fShKFeRfJbtt3aMTCpJCXh3erj7WG2te0ntbL4GSqOkFRH8Ocnqm5Vw0fiQkp0ZDDETde/hLyGoUub4M4SHAFfyOCNN7rdDGg6wf0QSsCxf39Mp6agAGCgfACkx7xquOEV0scZcFeAWt92kXqTH/VWFNA14NGVbFkqPcJDczHI7lL4ev1b2WGMJquqZ5eL5detx+U+Cd4t/RCmGm63/BckXxsaZ0OikkgU0W1AA0MTHJ+vruWGcnEjqP+QvDTOUTc78av0xl1HBex4EaIcetIlP0oeUe/NUZV17SvM8dz6ShnOuXA3HArTTvnZPEvRUsrydkuQpU9FeodY8mCRUmefqGJkOEGfrRUpYRwqsVONCkSp29YAEACqx2IAyVXQuINdtF/eshFgn/l6PTWfA02liLMIJLN4nTgkBoZtyePhag996v0PQJOxlD2usqR9KdTVZp5v/zlxb4KNv57Sz6Z1Nv/WexqxCagngftT/16SVOLx8LWNjC7GH/33oczZmQCw/ILMgpjhomHRr2oyL72/hvDqq9FJzlK5JosTud8YlE/F36N6Pn5u4wlyWZnVtgFuzAFYHriqXgdB5mcEk1sfVBtty3Xuk9yQKfhBxjRZNcFaQTuDUlU3gEOAwuxNYEVD3D9b7LopL+BqD/YqeE2hT6tCb0vxxVSPQfMUEJ38I4Dw8fhm4JjE9Jh5LHUJEQvzaS9CcqU2sLN00183rdEl6mG3o3FNiSx3+irxfRLvN91euOaorDVa8GbIP7h7VUOOjFFsH1rrUSTw="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": false,
    "sequence_end": false,
!    "sequence_id": 1741498993140
  }
}
‘Received response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["NOSPEECH"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Response JSON for chunk 3:
¡{"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["NOSPEECH"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Sending request for chunk 4
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
æ    "data": ["BJfkTD/w25pLoRnmaVND0uY2L9kxlteEgy5XZ8J9dz5MXj3HysXGvJmcq9lr6K43gjcxCo12LEJ0pTqFnpsHSimhyu8Ls5NisW36s/Uy5gN+MxoV4u4zk4JV1daIpjhx4tUImeVHsBLTc51sORH07pWohNacJu0Arh8amU0IeAXFRuy17vG6ut8rGkw/WBegx6RdFxzKy9fauPsZ0Dqve6MOHvbxflXG3cDEEmJaMzPWCqV0NzUguFHC9fiGNqaoUiUsyW1v1St1LPLX071aQMnmQRC2bWqKPXJwqfkw1SQqfP7tExm8/nfnHSQVo26Qa9Jc89TtITwwzMABRqs/eIkqI0xLmSBrVSrlun8bDE/MafLmwz688Jxpx3ee0DJoT6rDNLCXdXikvfmDve9Bl7/Pj6snY/xBW9JvCsgkAWJiJFVRj9hUlZ9abgRQtsitW0Jr5ZkR1cEnZZK9nYIVhyvNVXZtnzq5pJv+4wk6txh7v0rGJb9nLyPQ+vuLavdPGFGpSH7hWty0fDQMkjDtCT656nrMeeq3UBmVKROhGhUYUWYkLkj6oPdrjQnlQK4+h9rWpQOTfisZNwMuTB2UDSLvJvycA/VMNuoAedJZJ4x92+a9MhpCRcg4HcZdRw59rmou+BptXZ1gu4p2fljYzQxm0fo3JyYFDv8d+QaHlts6zfV0r3lckQWnmjPf/hvQYwqHluD0U6F/hH4kGCIeu8am8aCV/L0E3siLFkE6SB51Q0eOdMsqxBO2wa/4asgPWNqiYbu50tVDcYUGw7kgUXiLoboruyCjp9uynyA/YEl6ekRYQ0iSXbOVZ9Hb1JWXaIDUCbEmEPp6kNjuntWOXbe1qNYFxSY0UNGk687BCbmFGD3kpx28HbBLHseU3a17IdMWVQtVTJdg9SskORyWvdDmx0Yih5Un03j2drbsTqTOPjyCE3guS80pw0iLuwu+km+W6yocC7RMIHdCzz3Sx1amglYQK615pp12IYjZphrWjErtPDLuy+4fM/88v6ZgVyVdrKnaM+ecx/ybx4ixfOriqa3JVbZYbPPRv29xDbfxgV6/uSWMz4Y2Mno1e46U4mSLbLW0rfLeDKiybRV6HUt5KpzNb1bg3fEOWZEY5noV6UDo2VhQ70G90bxRK+t9DByU+6lDEhJBardv7eTv+J7N7pSBMmhV86ySScdA04HiOns7xIXgk/L5ivgzNxLB3KyDdO7yr8M75Ps7kY9td//iOijHdmmZV/VR0J4/Us7yIUJd1bYGZr9jGu8G7JfYluq6ERGGkJ17S+15PV5OtkidDonegH7MC00wt44DjABjjXY3NvTfl4u2KV9zyby2CEnzmyaEz9YRm7pkJ+sRLyEZCu97Rda1WXyY2XqEqKyi/YvsvT767aRqReDj/QVxEaoZCVyEf2Tcvo9I26Xm8EhGTL0pZCJ1/NJQFGgLTGd596LgB1QE2q5ctDv37X1Kc3XRQeGX7LE1TsgAbtaJLiMwDDHe0hjajGGvg4Gt+sRcybK/0/foa8+xzgFF40Lb2uaBR/lMdSPaBvHMAvzoPYOggdbfdtQpL7fgCUyWLxfwDnZkor7CzxxEo0JUPu/pLL7r/loHu0IdFJDNe6LpbbsIUirXJqXyfu8tmij9QufdnjGdjJVE8EQjWaXax0fAE76txsupze9Obu7RgAtyMOLcYpcy0rYuthxVOAjiAic="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": false,
    "sequence_end": true,
!    "sequence_id": 1741498993140
  }
}
◊Received response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["ENDOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Response JSON for chunk 4:
ƒ{"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["ENDOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
 Send request for VadClientTest
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
æ    "data": ["ncu0zStfsqhJZon0xD/mfz1ITNqZn/IU+9Xp+9FnZQ3COE1fI+78L/FRkdN0MTVfrDQyRofZ/xZzjRRqUAyFTpIL9/iiArw4lQbRs1gP26IhyjYrI9d9B+A87wWklExmZYu2EYHD6zkyLv+TiD6E00ea9SkuEDGf4j3lTOO5eotWp98VDN7cTifqi+a00UgpyRZGriD2T+a58zBA8qfOMcSqkYWFYAu8uNtql5snVVzaDW5jovbcz83bbbYNBAw20wFFTp9kBpWPvOUAldmXra42dwgUTk4EJy4sekVDCXvpDZ1JA4qyJjWH+dEK+s4E/835vwiqbSn1DSie/VDCEDEK8B/OQHEonS8A9/mijpKJQu5OxZuZCApKBiJthaljGwA3aRHk9r2a66grctQa3o3xV97F2tIvW624vB/ssL/ay1fLUKTZAmQLgfscoy6IUvPauzdXPw2D3+tjddrFp+Qw+wAEQiMwGGKPnLC2ClWf945FfRwNEEDVIPIh1rgfdv5gKBmYb2s1PsQ9exhlQUMyoaWvA98M89BTH6rLywsOROR1cPZh9h/yPxngURR/jleXQhc2Lf8k81La7pRgNu+VIWpeTHvEn+yx2NTajzfVqEXRs39DRPxaJvObz4FhoGHx9ywjm3RhYVKgYdif2/EQysW3cceXytYr8bQDQAc="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": true,
    "sequence_end": false,
!    "sequence_id": 1741498993211
  }
}
ŸReceived response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
·Response JSON (512 bytes): {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
Í
    "data": ["UqtOQa7KxEltenCAPaLYknkN+zN6Mgmc6iCa2s3BbVFXbqB8mYr5RUp4i7+m8ikAAhXkpZ/IUflYB/9RlStoxy+tkDfas1zEFt0LaLe5gKn7CI/yyH2ksSmyPlUHUKyj6LoChsntLwtzPNniOPxPmSXMB4gVFLqzAZlA6MQUU8QRE59Q77e97CjwzZJEdJ1FAu4qchr1DNjqt8KJApbt00FmtjiMvEBSnThU28xnG4JZ/1xkYSzTn8432AgK5dVRkbbJSxLzcjxi7VbEEs82Qrb2J47mMU3K/qZkj7sWadMdhElQp5LuOKi9Z5wwy1N356Rwy5mEM0iuwZUuBqIEFIYJXlWn1MpGxgA9dI9ssuSAOTZl3xRNhHbKnRhwDuGKcojK1yCHHki1FunQcMm1t1jXDYQSf3gP0nIwGZPyI0cLpj0+VW9SaZVYbXxnZIcQCjnMqfwVsn2jU4TMnELDw3zXoKc8fG1aJpmK7triUGx1ZQ8EYL3gqK312orP7hM+eN44BgDJxNFQNfFhhhOGDzx0mi1xlHOdF2rR/P/RHduzValKf2+5kpu0Mkz7RPkjR2K1AFlwGizucvvSFvAOkWZNLfLMKm4et/kWmRvssztA9gJxtCYje6E7iymTBGhbz/eWo67Jnkf2Aje8n5rNThe1fv8SqEX5hqEHtwdhvLmvZeimIHEDHs06/2WSRbsXf+aUP3jq6MJUDFMDlxsf2spSl+vPrukIV1h7a9Pb0OZuqYYQ36Mq4qfWhIp9jZcZagLOAZ9b7XPSz406mCzvoqEYjKK01DPRgEZX3YchN7bdKzvjJ077Ix/TdAbmHZiyFn9mG1cipE3CFSyHlnKqp/L2Qqgw3QcmRuK+shoz4/WPnFSynAEe27aK6b8hul+UgAijTjkyI0zw6xBlY2MMzxb6mmdNsT1KiCAytq+OnMLgntuG9mvVWOv9X5BFQJd0dE4SEKUEhTjHv7iMYPIctm6+7xXNkOxLqoWAPhdsQG248m1J1v0FxemGs/tlsRXkC25OuVdRJr/DIC1XhmA3I7ZmLBCEONakxSKv5YQQtIieA/ei5Zpf5G/95qUQhVrxheVjHEkklVkXt0QVlct0Mo6AKpT5+TOCDctRaoqVb+oACt3eLw+Pi/9WdMcHZOwISv47VcjMNj+fOu1Qm1iS30aDLfQ5AEdwgg2mnFy/2i3BKlLJv0Uwp0sPTsw+plPYO9nEJ9phcbUIdpMIqBWk2OrUKyX7PQiZ27446US+QkQFQR2te3ypn9zkm18WMIn1Pok54M/XSDc9oj/i0O7aqo+Bggn6wGvrrx9FLmP3OCM5Pp7PQvFiCAW2xunZig+ECeggRSbjHoYWpuqdYVKV4g=="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": true,
    "sequence_end": false,
!    "sequence_id": 1741498993220
  }
}
v14:43:13.305 [SessionTracker] INFO org.apache.zookeeper.server.SessionTrackerImpl -- SessionTrackerImpl exited loop!
ŸReceived response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
·Response JSON after reset: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
