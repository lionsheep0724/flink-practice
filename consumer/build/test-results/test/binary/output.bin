Sending request for chunk 1
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
æ    "data": ["NMgCLRg+4UUEE6huGt3WOgqvU0j6/Q1KT3MBpcqJbRy+1/gwnvw8l0ydGA3esWkpInxMCqFxmkPf/tqzD9tFU2kqgcIe+3ef6mNUnSZkDPLqwsEFHsKZYKqzN7aJAOjFJA4t/E7yzFJgoGulGNkHuQIv5ujyeEEnMy3AVzlmZJhfdUMUGj9MxVQu3KIxVy8ty1S5QxJT1udjJ8D7tRqKQo+Dt2cetRDeESwu28DcwwjuhYpmZrtL6wWnHM2nDRnarSm00y9BTCwDK1Q6asb74dW1UYlLFWi3S7K2CkyejWC30k4V01tWMz/wsD2kxWjdMW6QmhLXN6ZHmTxb9XlfUC4gM4fDSyY++MTkJDwntiFy06x4f3TZPXPOq5GJys2Gl7ZZ/XA4460LV8Tj0Wl5oVK5+ARKGeyMKk8FcgK1knD6GRyvfAx0wnQpG5tWJA/tS8fWc6IzK08snPaz6ycYEWaaNxg8KDkP15QbsJM8vkMcra95pc4AxR5Cebfp+QcVa1CReT3kWSn4V570pG2bCEhnqXjovBj4CPKqHS9YUaKeKc0qvONPoEO4k7R4HucUlpNSn/WSPp7VKWC+CIX9ABkFCj4sN5r8RTJI51OI3x6S1bP8yHEQ69ZsM0FR5m2J+N9UD7ROwlMwul41TC1BkQtLeepSoVBoQAwT9/tj3X3dEaU5r7wc/FuMov7Qnu+8kxAm0vf631upf49vjhY/lmyZcxMqyO8NwI0SDR2UgEMC1oM+DySrWY9NbKuhRdQO0Hg/RWnP6ap9PMgsyFCj9vOCwF5omBRf0YM1vGO2E/s0IpFEYnoReFMwnHI4W54tRuvrnMKEpTw0wNsWFUq8d0v0Tn5AvZlRKiuqlSiDXb+ck8etUnEPIt/ImN2O7CwYycZ0w+GqQwOLuRZiKTjKZN6FGoxAvMjX37Se67bSW5TohoAbWRc4uyRjuPUdMGhEtzX7JSjkzZCkpFN7CwkHTuTjJXhtCoMASGuGKb1dcM0VdcEenaJRRoIKHNYfUvi8fwsb5hkCmzFtIe9EFTfk1ax4kuyi1mU+MYP1mhdVdjN+dhC/CwWe8qzBd9oDTFMkc+y4xC8/57VOPmTPLhw9tSnFJRElhS5+ROVHd7ssTSskGDs+sgU2pdj2dBww45fMz6tt6P4RGn8Wg4KhRaC5wcATYU6LGIU+s3vVT/81dmJA71JnYtsz9CqAjnv9KpEQCQwdR45VyhMoyEV3El+Wn1Fx8KLOAw2jKtCwRBPlr8MHl4fLhYSZyWOs47LxJR/GXE2uCPXCdMniJZrZCaG8yIQY4kKsIXTb9AUTKbrdQsS9BLaqPVjqEMYzykk4Yl6MkDbRLjP4Vz1PiARdn8PF+Va7DzFDzWpCbHzqkEsjOrP9XcHtwIyWlUwVHYdmrYFLDIR6VVOIRNwNs4KFwexyweNWp97qVz9hp6W/dOcHQSlHvVHA8K7adgmsqBhvO6YAHumOj7/QppSBwTvjkiWLm3Z9EdVSWILYYN2NFPy2njnLkKmcP0fUMN2I4j/m3DvIiQ9MfeOP47M5bwyiZDg3hM9CzynejuDVJEyENft2AJ51fyJJwSeIT1/clf92ICiFUEGjbAZ5j5GhtNh1+e0TgLQ2kkxAW4LAviIl/lb+uO45AM+Rkx+uCAZ9k7ufe9Tcwqgp+WVBVfXrgxYL+4WQ/rsZBWRV//+g5rknGL13DJM="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": true,
    "sequence_end": false,
!    "sequence_id": 1742224659836
  }
}
ŸReceived response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Response JSON for chunk 1:
∆{"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Sending request for chunk 2
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
æ    "data": ["oQ/202sPiYma1QbIstYcAMdSvn+R4sSAOLJ7PrqGCOtWOLxPQiuVPSViHHSZEU6QlK/iioCbIRDaRw+iDhjVsWlfzkMLDgr6DFlbtCVAnXwfmNDbz471JwzwVvDJND22aR0RcJ32JHhvz+eanYqZnKYMdDceDudA8TtNoAueZIBmYwE/BGw3BZZQVyecvnXyLOpf0oGCsMQS8XwSijsXnnWHzX78j4xZav5z3JMlULT5PhuNAmf4GtqxBQIP2idHMGHTGnpBtib5QRNyRKsunRevFHgcEz4qGjZd1fk5eG4zdhX3JA9s1PUL4htIVOkJ1ujtB0JVpcyHE8+zuG2EjaA2ee/T+WXeNqVIWIoEffNIKREHVt2qJzcW/SJTiIuZnEngpBgH3Wg0D8i8ypWAzcbQwj0ydwvtKCniVeObr5rQ6W4ytaOb7I30cr8cPrasaQch/iMVaEq5zhlFFginTuhRkR0g1sdOhSlkD2ZG896RccM9aKpwtC8pbh6tGNkZFzmS0wNB0VOBvFSo5RDYSmL07Kq31Z/JMpPul/3z/0qSX9TPvvUsIIuWs2+obxKDQoqBN7lb0T9NyBA5ctmpXhArARbkFslk0avg0xRLJHZdJzLoinE9L3GdnroIsDOBUVO+A7pKYugmvG2YXpjoCCGukFI616IUcklyNNDkFgeUnrydu/0kWoCjhrQUoFC3wvP9GE7CqZOJPUPucZmk9B+uMWQWdUS9eDrj6pWUE4y31KPfP5jJWdCNBU+kIoj3utoOay6xcUjNxuSMlHhKXTtZ7an5eDuByemdlLfWqmU0IYfqGSBcR+H7wKyZVTJBzekuTF6Zw3rYJOyzCyxT7t0etrwiIKZnOovc3H/Cjpuwk3ChwW1b1MRObv+XJ5mrCh56RUhS990DRbd897lm+WxdjIFrpAYqOlz++GIbiiuVMtMRvLwW+4jIC34EwRUuS6sSCBrwXC1KX2wBDLWV2VpmWRRnvTYcvsQEf35d68nds6aYfaKS9+hP925GXB7qu/WbxGHM3Fy4yKkQj9zSD3QExTG5FgrJbGTm8VXhRosdnHuPew4PFDOk5QI4ab0EqRUmC+frt/AS+sQUk3tXp2nw0fa2t7HxC1jImc1yyBDV7y4xkw/k1HsNAxTuF1T2jNH3dso9PoTDluahdWNa75nfIcs/mBH+K0P8Pmj3nXX34vzIoFo+CgLV+HOrpq9YVzoB/t5vF5QJgKeSlZ26nR8ZomDY3jS2EeobGsD/keS2MlbqWc6z9OERcUQgD5rX/lVpFURU3vZeQFXzVjA0IyG9TRcOhCTq5WcBgkZg9sOQFUy+a3Dz6PuVPGTm7mvOSYTduUsUjo8oW/LAWZOm4Fgq6ycHV9fSH03tXTstxEKf7eKq1587ICIHtZc+x/742IlJNYes222kTKHG9a4hJdstbotqnwHGLzIqP++1l5ccKWQrjngEzIdwlxkI8PM2eG2rijFuTfoQRq+K+4IXYTDpOCBy2HXcbIon5jpbLOA1/Rt9S6SrNGjYoVoB2tXYpZMORr6B9esY8iUwqNB145WaEXlOQc9wP8ObSzhddZER5w9UsBQqAvWl+BVBfGYGYMSd+MKmY42Dzemq6mPMNIuzi528PoKnkfv/ikn8pTQgH2eVpGIzpIPj/ob1CLcfMwdsgQet7XIf4DRn2NdByqXpFs/lyW1Dct/lCEmJrIc="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": false,
    "sequence_end": false,
!    "sequence_id": 1742224659836
  }
}
”Received response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["NOEVENT"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Response JSON for chunk 2:
¿{"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["NOEVENT"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Sending request for chunk 3
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
æ    "data": ["qGq2u+zO0bn0qB6HWUWqPoGBUPHpYhXf6uHzIWzyMUGQLSfLe2jk3wt0gjkLQRFfjfdkGgkg4ehmOj3/+SCERxTDOQ319NUPghhuwoPzJaRitDSYEWoavMbfjqIcDxMXYC4wa1HZ9Zgbp4BNKGhm9OEs8UzC+kHyz3judhhzqMUof+tyu2Y6ybx6kkO2k4FRrKawkVGHhcSp9OK0wa1ThB5ep34PrVbe79gemryqg4SqDAYZ5jpQ1V+zB/ECCXXgfanqHmIdyJNjIhFdHsjG2YfTDqgfAYAcYj6sPVlGgqqBIT9SevwF52mT12WT4+FiMe6oGIqgCbgHkYLeVn1e4uwkgjZRpTzmd5Td7CgYEAJc0sL7LqUVEgTxnasgSl9qg33gx5abPsGpms9kuzrKt/+M914DG+Ak91ZE5+9LWYuPPM/xK26V3zuYStmAwIxI1eborHUY5aPfZlR4k/NNhV2nk66oadxxEP3Y3ID1A1bemAlc5RgkeaH4QTHsoZSBvjMsMtcaz88uR1/sFYMYdNuQySMoJ4RUhDDrCW8WmTyIlKwlNqG190AjWhBwRpaX1UVWvAbYogK1J8j4qC2JphPWXsh40RivEh2QbhN3Z3mWHGHBvBSY38QkN2ay74uLvIo7ZAQo6BcZ4BhxVx2eLi7cnSx7tXgBJWTnCsHuWw1lB4vjdIt7COkH3CHo2MVCcDLrAObroaWwcKRomPVeWfOvwX0Y3xoYvIDpW0T3NxdySFcrmH0XAyIMBPMTBpWPz1PpYXFl9Rzyd01+P9prJxFnclOczn7jmqe4a5+n+D9mmin9tvKyy4vcQV6Brn0XaquhUPO7gEscbIrsvYUqPal/QfxS7whEr2/fUAZyZR9iy2M+EkacChLTOJeDXoLEjuADb2Mq/ZgmZbBGnUqYeiDqubVhC7RBxc7G6RpB3ySNFymFPXzAzuGTxh1qLA4BjXwmhr2S4M7ogvNDQRzRHiOpBzTmOEtbbzY3gWXQ5fPbPfRk9mVRFA6N4UDInPUxUgAGtZdyJfKIOx7n2fogVfszt21S/Ea/L90uJhZcouwfO9c0QQwFR4Ymi4DlETPXJcQ5+wh1bwsnHv/PpF42HBMH1TsFnCt+53/5OP4DXI5U10dUxiEwfjeuui+A4qxtu40IULsdrjTN1TY1a34JE8cOCuQs4aU8gieEqct9S6cocbQRbHUQZn5M2JvIc7ixggjjOU9JZu6ReKZaO42FJXDYcZvYwd735L6h04TyEJrLswDZN6JLltCMfZma8m6uK4wyP/F+Ll8Nb4DOY0s2vK21E/RgsNXpD4WbzUUjWAD2IrrRXngxp6xG+2n8h4UoeN3ejT1P6XYBgCwVrYZtufM9YJb5i0Qblqc6aDsxPFM/qZAbsNv4VsDy2grZJHRXSNUthVI8JPpGzAkH4WXBkljaGLKUbt9FR5G2ZeOk/ReblKcVKRMx41u4c8T/QIuM4Bns+zTn+LH3xt8ad5utcp1H1/D30+0hFbndcn+Q2gk1reew0MVAwhO/+R5XKWrAfFZm7WZ+IZfbdcFYm9vG2no6Rw4f1oFeQ/2k49npkWNuUtuA1SBHwreQaLpkuVQDFp3e2Mip4PwVhoQzZzGRbi2STGHVejVZ2NZL1jx3kGs1ygnI6OJKV3eXjx3+m3BXdt4Za65vKO8PAfgOXA/nsEXFBNSPTpUyP/GxNrDrNsA="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": false,
    "sequence_end": false,
!    "sequence_id": 1742224659836
  }
}
”Received response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["NOEVENT"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Response JSON for chunk 3:
¿{"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["NOEVENT"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Sending request for chunk 4
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
æ    "data": ["iS5//ttIlmdTBJq3T283hHukncZCz1IQo638liI3OL2sdBLxich6VD3ylLp1DlY1TKVymXsXrvvBqemdDmisS6h6ft8cDALrjGnDG4HU/Kn0UC6hJDTQoBl+c7fCCSfcSs4MJKs+veyjlkYq/E9hA/Kwc0Eg552FDQcEEqBnyu3jvdD2fxvLvgbEBBC/POuiipNs6cPR1YlofXtznPtPuMlkhUSYQJ7r4Xo5T31axRNC4CtlVG/Zy9Qe0iHBLEDM1MdwmShRS3eBM7moN5NCnGX8VSSS36quYmYWIqxd82HiAd4VFeiIwdiVytfFcVHfgz/B8iyB6QQG1cnmD0s2yVOAAMJ7Wssr/Um3ilTodwPvdwDESFzXUxlK3uQwuqsMjU9SvyhKJl2qWHYB42YRSj9/CZ/9XLG41evVbGd3RWV5d7/FHwjeyLwbEsbFQcne0N5pa9hd5Dndn8eTo6RuiwRoMBMWx9IPt76rBCFoi+xAhLtdWwLpNLITSu7mV8FMn3VFdPedL/BATz4jdWplsvKFSwV5YdAoPlWHXcSJYQ7AZVVVY1oHuqBdg1sP0RFojfckiRyAy1RN+/o06VNXDV8LAdsqI8mqSC2bQ5PCJz99zvF2oJs3gQ/enI2Qf4I/evPt2dTqtiRHdVpkePoos3HWY6JVRPnQmF96sQxkAbGRIXolG7LHctawXzaKD+in27UX+ABIMKhhRAApQxUlGyrcehVvmp+szf9RIWoKAYtzAiTTWmyOjMQbdxkt4kw7TolYU3HIh1krl+tiCUxeyrVlxliQ+dpigzh0UlojQyEKmxn3eBaQpJHBsRUxxAN3XtHgmcEUbZRBOUGeaVn1Re+LLr0Pl0RPx2986fx3mtjzwzi+g+qmdgchfKeSm6G8k+sQpnTnoBM3WS+CWlh2CzmdqklfqbvFwf9xDB1W0zkOewehG1Ir0W2sRtuQaBCAvgLDn1BMSiO/KvYG6VjJ/H5ZofsqwWG0nU8ZgbQ0L1hPVHBGSDWXUDUFuGXmNR/hg0C6L/qA4oIdsfLqMpg3K4Awvgysl25Lu1hZcpvv0//D0BlSnNL6WeYnZsNK1F+wKAnNJtOy+YvNPcfFofcHUGfu/9NSToV4F+R9do/2virhx3eEitwQYUuUl/olfQypnS0wghEWQiByb6fvaY9yOIyCWSSTW9TP+wtto2oLnmAUT06sBtgSNt29fwuUuFTTyz8l6SESlmoCvaPpRXhkgYPMnScOocQL483g459r/OaGy4GDXfhdSm9QyL6fIhI/InV2cDx/Uakx2dLGbigC3Web21blZpO1sLibmfeAvN4uGgCGV/TD/hkVQ1u568LlXcPe20gxlQUbeqVN3f9Hw2pLBzxZOCajEgOiMIt1G5Ed+orni5BKDGeDlqp4MAGvmSP9pvFLJyg1Ucu4w9/Vf5ytE2qn3faRMJb+NgFHvZQFJXT2AttflcJK2XWWhMOTlif+rAgc2oJ2PxaIRukbhPslrIoi72BRmdjF9ws1vQkLwi/UD1RoCx5gn24oTcRVTU3/URxy9pnCEfsffb8DVrwr3mmRvSExcEUebx2nt73OHkKDboBHsOVbNQMdxrpwsryTCVe6VW2XUe3BrugSU9mXaJrLi74I0xtZrG7ld3242rnSnKBabiQ07WX6ztnty1sCFZtN4yH79R31xyogXtxtWyeSVQRrjLLTpjJBpXQ="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": false,
    "sequence_end": true,
!    "sequence_id": 1742224659836
  }
}
◊Received response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["ENDOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
Response JSON for chunk 4:
ƒ{"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["ENDOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
 Send request for VadClientTest
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
Í
    "data": ["+kSEXpu3kv+26FAfI5u8phlSMAmgQ/ZqucYLLTaC38ibqJS+B8QlUZu35fRzuJ5tfUSRf4hL4aCwdS5LnpXYhEReFjRfHFB2ruFT7NUO0b9Bw8mfO1VkKZLepTObLlXIF+5yxHz5l2XEhyG0NXoVA3qj8RqeyHV4eSU30TTYsHk5F3vt75iTRFiD0NZTzG7efd0VP4gpy45fjRMMghxBvFIsDT16n9m2CFe3HUIzku5nMZgrRiJd2qfwf7Ez0+YeEYB6D5NLqxQVr9dO6++ux5XbLj8aXnIuksnCPgjACrWm4X1H5HfC+Odx1PGIXAYbLFl2rbczO4/LypqbV4EfnkYp1ZrNbe1Xh2BpailDDmySPEc2xx9IRNwHwFaJzgIpq9TPnuGHYkAkRwZhMoQXvvMRQk1lD2UEtq0xBZ0G2FGRs2QYZKT1cY+9byTbDLMIvVNDnKR6oxQtS1L7pA420jqkoDPUZ5k7vneHaa8dTw4kb7GvBk+d43qpFLVDgMJc61+ALl1P1m1MJp6QDeHGZZ/Y1scFqjoBtzS76DQolOZtV4ezY5Mhvffm8GGqUd4kaTC6Po1jhFJm9OttxdT2EY2fpZj82T2iIUU0BQ1x5J4BdyaugGhNCOsTG9lXdGrnnO0+93O5D6JRyk7SEs71F6pR1QUx5bwuDfuN6eCD9wrvo2SaxwqQ6a8epXtoW5ki7F7tDek/A6N59niuas0yhWDulJApDMZVi7mZ/BOWsZoRm0ZmZuPD2z9w+ZWSdooIy+6QRoJT81LWISKp6vv71ajUJu9X2f03U7jubglftlSS+Rvx6pBbeae+k7Ua0pivBjForOE0fXcNXfPEFs9l+xritTMyIVJxtzcKkKE7VYnAwDugHU0fl6oT+eMTdoRSTFei4ltwd3PlZQlv1J+xOjMk+s6Xx3OKyDBJP+y4sNEVUM92HSxQrbTTPIvZYN4q/D+0mdFyhDPusOvto1C9ceaHbEphRqDtyM12lC7iKICAAXbhvvDNiALRtmzOOFjmNAtG/cfHMz9tA1EUIN+SZGUzbfFHMbMQ0TaJ3BfuMLP50zNwIXL/gxC3EJtVEY7cF2JmAsm89biKqXCBu/w3LzF2MJ/2MsO1w36wxUMnFpJE0FFGlc78l0Nav10M39GBXtzoQQBmmCy9lDFmtgqjQ2B7ws5vP/VUc7xRYu8rF4cFFNeCrucVL9i3lllOd607IjCZTRBAFMt27obTXxV8US8qOk2j9/MaEpwq4f7gv1IFr02jpOOG+w2yrTDoNnmw6Rd9qjXrWagM6/OmjqpNg8jgh2pNetiI2/TnISy0D73Evt5n768/JY7UeO8arMoD7xr7NJ672cXp6MauYqdC7g=="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": true,
    "sequence_end": false,
!    "sequence_id": 1742224660125
  }
}
ŸReceived response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
·Response JSON (512 bytes): {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
ESending request to: http://localhost:8000/v2/models/vad_model/infer
Request JSON: {
  "outputs": [
    {"name": "EVENT"},
    {"name": "TIMESTAMP"}
  ],
  "inputs": [{
    "shape": [1],
Í
    "data": ["eCsQzV119DaySJM3wcE/1LoRUoTsTdgSWSY0mU1/gGF7m483DjwgDQh4GxD88lEA80URyW4PZntWUkirS3CQ5pTob7KXcdBj1getwzNqeJVel6wptrsFO4hFUhGJyBk4cNYzZ6TkT3iRAivqp6/g3uHypyUkywKGLjcL80ye8MHQlLcFaGCGDeaO3kvABXmYud4CN9p2enT/iVuYO8D4qwquYiQYOYIbMsJCuYcJ2P310Ao7P42hW6FGAQ/k3RbiiEU5omvo9qwIQ4hgK+NHRfrVsZl+VkDlM2abHzVA7jxGpmaJIbpCLq+7+pF9Btfx/YajuQiJFpDE7OMrAxJtwlghG2p5iM2RohyyH3ODkCGMUJIcDk4ZKNnTIj+GOGkTYjzXhriI0pUOrznoqOY9vwYJd7QHVr3x68Qj8du7z8EeMH50qSfnJ1f3FqfaqVRJHte8nzD9vrfnozi7gb8oedq2yQEY9tBak2da2Ws08bFcaJN/B4Aap6zpEgbcCnKZ9yr5UlalfKMN4qNf4WsBtpx34QjQPybpkM59hrYhkiJr9dUfuBMoGsQLRYpn1ADsjKORRRAXATjcREN2uezllEBMZ+sYaRFN6W5rZ0pB6LQylTM5FL7GPUvDxdX28aq5E0Hv3VJDPcplbXx+fBUzLGV2K0FrPzxrj98YKmEdSByVHwujyPIl5lADDZ8TFBwuT7jplWh85hbMuKIaUhm3Ww4cEU/fxmVte1kfDcvAc43xKeXHocG8IRsykOgFN5Bh1VEF2IBqrt/nJ5AfgFCynJ9eUfBza+kSCf2l+RvnevrZEcAfmFCfikzo3Vi2KSdAgGTLknuaSpgVdDiXF8IEQhuBH+aYME1bk9izHRH1Z9kPy3baHviknTVFVJHiICHSMYdeO/WSjIVczeJv3T1hfp35RPICi7q4UexhrUhF06zFDOszqW1RMHnUsX+HoqoYzNVgtZObt3zH/c2meRLFZBSKVbCw0LUucaeweCGVADwVuvjZf6inY+ZAgA+JVcwfcOUzBYyieW3+7XWq4qsFvUO84AU6a+Rgc5orje+doKy/oREwwmwNJY9Q8xCkga1T9kPH8XvssNsnx8DHCqZDC/lcxw9bOHoQx1pJS2Um894i8fXcvahyxS7mjdyXS951rZ7Tx2R6uOH8LUVDxh+9MY3S2Bi/xDq7qdPUUDwYFC599o4PbhBI7LkD8iKP+RCrVOzFYARSkaYtU+JNAVoPEZ1qVa8OTRuHPIDouClm+D1mDr8HVKO0HUIK8GfSy8c6WDb/1l4UJ/f51EUXIu+59wf7J8M5sb7X5kpbUP7NRc+L2EJKewgqzBWzdAytNUeFT92q/oOOYuUHrvqauy7kVg=="],
    "datatype": "BYTES",
    "name": "AUDIO_CHUNK"
  }],
  "parameters": {
    "sequence_start": true,
    "sequence_end": false,
!    "sequence_id": 1742224660144
  }
}
ŸReceived response: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
·Response JSON after reset: {"model_name":"vad_model","model_version":"1","outputs":[{"name":"EVENT","datatype":"BYTES","shape":[1],"data":["STARTOFSTREAM"]},{"name":"TIMESTAMP","datatype":"FP32","shape":[1],"data":[-1.0]}]}
m00:17:51.995 [Test worker] INFO org.apache.kafka.clients.producer.ProducerConfig -- ProducerConfig values: 
	acks = -1
#	auto.include.jmx.reporter = true
	batch.size = 16384
(	bootstrap.servers = [127.0.0.1:54143]
	buffer.memory = 33554432
&	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
#	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
P	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
,	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
 	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
!	metrics.recording.level = INFO
#	metrics.sample.window.ms = 30000
2	partitioner.adaptive.partitioning.enable = true
*	partitioner.availability.timeout.ms = 0
	partitioner.class = null
"	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
"	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
,	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
+	sasl.kerberos.kinit.cmd = /usr/bin/kinit
0	sasl.kerberos.min.time.before.relogin = 60000
$	sasl.kerberos.service.name = null
+	sasl.kerberos.ticket.renew.jitter = 0.05
1	sasl.kerberos.ticket.renew.window.factor = 0.8
+	sasl.login.callback.handler.class = null
	sasl.login.class = null
'	sasl.login.connect.timeout.ms = null
$	sasl.login.read.timeout.ms = null
*	sasl.login.refresh.buffer.seconds = 300
-	sasl.login.refresh.min.period.seconds = 60
)	sasl.login.refresh.window.factor = 0.8
*	sasl.login.refresh.window.jitter = 0.05
*	sasl.login.retry.backoff.max.ms = 10000
$	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
+	sasl.oauthbearer.clock.skew.seconds = 30
,	sasl.oauthbearer.expected.audience = null
*	sasl.oauthbearer.expected.issuer = null
6	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
>	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
8	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
,	sasl.oauthbearer.jwks.endpoint.url = null
,	sasl.oauthbearer.scope.claim.name = scope
(	sasl.oauthbearer.sub.claim.name = sub
-	sasl.oauthbearer.token.endpoint.url = null
 	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
1	socket.connection.setup.timeout.max.ms = 30000
-	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
-	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
0	ssl.endpoint.identification.algorithm = https
"	ssl.engine.factory.class = null
	ssl.key.password = null
%	ssl.keymanager.algorithm = SunX509
(	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
*	ssl.secure.random.implementation = null
$	ssl.trustmanager.algorithm = PKIX
%	ssl.truststore.certificates = null
!	ssl.truststore.location = null
!	ssl.truststore.password = null
	ssl.truststore.type = JKS
!	transaction.timeout.ms = 60000
	transactional.id = null
U	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

ò00:17:52.004 [Test worker] INFO org.apache.kafka.clients.producer.KafkaProducer -- [Producer clientId=producer-1] Instantiated an idempotent producer.
e00:17:52.019 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka version: 3.4.1
q00:17:52.019 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka commitId: 8a516edc2755df89
q00:17:52.019 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka startTimeMs: 1742224672019
í00:17:52.030 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata -- [Producer clientId=producer-1] Resetting the last seen epoch of partition audio-packet-topic-0 to 0 since the associated topicId changed from null to WPqPkxUST_a8MdkfLr0DcA
ß00:17:52.032 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata -- [Producer clientId=producer-1] Cluster ID: T7-gidndTtSBklyAr_aMhg
È00:17:52.039 [controller-event-thread] INFO kafka.controller.KafkaController -- [Controller id=0] Acquired new producerId block ProducerIdsBlock(assignedBrokerId=0, firstProducerId=0, size=1000) by writing to Zk with path version 1
¬00:17:52.042 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.producer.internals.TransactionManager -- [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
ª00:17:52.042 [Test worker] INFO org.apache.kafka.clients.producer.KafkaProducer -- [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
e00:17:52.099 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics scheduler closed
â00:17:52.099 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Closing reporter org.apache.kafka.common.metrics.JmxReporter
e00:17:52.099 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics reporters closed
Ñ00:17:52.099 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- App info kafka.producer for producer-1 unregistered
m00:17:52.105 [Test worker] INFO org.apache.kafka.clients.consumer.ConsumerConfig -- ConsumerConfig values: 
"	allow.auto.create.topics = true
!	auto.commit.interval.ms = 5000
#	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
(	bootstrap.servers = [127.0.0.1:54143]
	check.crcs = true
&	client.dns.lookup = use_all_dns_ips
$	client.id = consumer-test-group-1
	client.rack = 
#	connections.max.idle.ms = 540000
!	default.api.timeout.ms = 60000
	enable.auto.commit = true
!	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
'	internal.leave.group.on.close = true
<	internal.throw.on.fetch.stable.offset.unsupported = false
%	isolation.level = read_uncommitted
T	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
&	max.partition.fetch.bytes = 1048576
 	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
!	metrics.recording.level = INFO
#	metrics.sample.window.ms = 30000
ù	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
"	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
,	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
+	sasl.kerberos.kinit.cmd = /usr/bin/kinit
0	sasl.kerberos.min.time.before.relogin = 60000
$	sasl.kerberos.service.name = null
+	sasl.kerberos.ticket.renew.jitter = 0.05
1	sasl.kerberos.ticket.renew.window.factor = 0.8
+	sasl.login.callback.handler.class = null
	sasl.login.class = null
'	sasl.login.connect.timeout.ms = null
$	sasl.login.read.timeout.ms = null
*	sasl.login.refresh.buffer.seconds = 300
-	sasl.login.refresh.min.period.seconds = 60
)	sasl.login.refresh.window.factor = 0.8
*	sasl.login.refresh.window.jitter = 0.05
*	sasl.login.retry.backoff.max.ms = 10000
$	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
+	sasl.oauthbearer.clock.skew.seconds = 30
,	sasl.oauthbearer.expected.audience = null
*	sasl.oauthbearer.expected.issuer = null
6	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
>	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
8	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
,	sasl.oauthbearer.jwks.endpoint.url = null
,	sasl.oauthbearer.scope.claim.name = scope
(	sasl.oauthbearer.sub.claim.name = sub
-	sasl.oauthbearer.token.endpoint.url = null
 	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
1	socket.connection.setup.timeout.max.ms = 30000
-	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
-	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
0	ssl.endpoint.identification.algorithm = https
"	ssl.engine.factory.class = null
	ssl.key.password = null
%	ssl.keymanager.algorithm = SunX509
(	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
*	ssl.secure.random.implementation = null
$	ssl.trustmanager.algorithm = PKIX
%	ssl.truststore.certificates = null
!	ssl.truststore.location = null
!	ssl.truststore.password = null
	ssl.truststore.type = JKS
Y	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

e00:17:52.141 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka version: 3.4.1
q00:17:52.141 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka commitId: 8a516edc2755df89
q00:17:52.141 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka startTimeMs: 1742224672141
Ω00:17:52.141 [Test worker] INFO org.apache.kafka.clients.consumer.KafkaConsumer -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Subscribed to topic(s): audio-packet-topic
í00:17:52.149 [Test worker] INFO org.apache.kafka.clients.Metadata -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Resetting the last seen epoch of partition audio-packet-topic-0 to 0 since the associated topicId changed from null to WPqPkxUST_a8MdkfLr0DcA
ß00:17:52.149 [Test worker] INFO org.apache.kafka.clients.Metadata -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Cluster ID: T7-gidndTtSBklyAr_aMhg
Ê00:17:52.155 [data-plane-kafka-request-handler-1] INFO kafka.zk.AdminZkClient -- Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
Ë00:17:52.161 [controller-event-thread] INFO kafka.controller.KafkaController -- [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(WMeU4zsoQrScNSL1RW_Opg),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
00:17:52.162 [controller-event-thread] INFO kafka.controller.KafkaController -- [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
Œ00:17:52.162 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
Œ00:17:52.162 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
Œ00:17:52.162 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
Œ00:17:52.162 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
Œ00:17:52.162 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
£00:17:52.162 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
£00:17:52.162 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
ô00:17:52.170 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
ô00:17:52.170 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
ô00:17:52.170 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
ô00:17:52.170 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
ô00:17:52.170 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
Ω00:17:52.170 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
§00:17:52.170 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
£00:17:52.171 [controller-event-thread] INFO state.change.logger -- [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
Æ00:17:52.172 [data-plane-kafka-request-handler-3] INFO state.change.logger -- [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
ó00:17:52.174 [data-plane-kafka-request-handler-3] INFO kafka.server.ReplicaFetcherManager -- [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
Ò00:17:52.174 [data-plane-kafka-request-handler-3] INFO state.change.logger -- [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
™00:17:52.183 [data-plane-kafka-request-handler-3] INFO kafka.log.UnifiedLog$ -- [LogLoader partition=__consumer_offsets-3, dir=C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846] Loading producer state till offset 0 with message format version 2
‹00:17:52.184 [data-plane-kafka-request-handler-3] INFO kafka.log.LogManager -- Created log for partition __consumer_offsets-3 in C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
«00:17:52.185 [data-plane-kafka-request-handler-3] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
…00:17:52.185 [data-plane-kafka-request-handler-3] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
…00:17:52.185 [data-plane-kafka-request-handler-3] INFO state.change.logger -- [Broker id=0] Leader __consumer_offsets-3 with topic id Some(WMeU4zsoQrScNSL1RW_Opg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
™00:17:52.199 [data-plane-kafka-request-handler-3] INFO kafka.log.UnifiedLog$ -- [LogLoader partition=__consumer_offsets-2, dir=C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846] Loading producer state till offset 0 with message format version 2
‹00:17:52.200 [data-plane-kafka-request-handler-3] INFO kafka.log.LogManager -- Created log for partition __consumer_offsets-2 in C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
«00:17:52.200 [data-plane-kafka-request-handler-3] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
…00:17:52.200 [data-plane-kafka-request-handler-3] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
…00:17:52.200 [data-plane-kafka-request-handler-3] INFO state.change.logger -- [Broker id=0] Leader __consumer_offsets-2 with topic id Some(WMeU4zsoQrScNSL1RW_Opg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
™00:17:52.216 [data-plane-kafka-request-handler-3] INFO kafka.log.UnifiedLog$ -- [LogLoader partition=__consumer_offsets-4, dir=C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846] Loading producer state till offset 0 with message format version 2
‹00:17:52.217 [data-plane-kafka-request-handler-3] INFO kafka.log.LogManager -- Created log for partition __consumer_offsets-4 in C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
«00:17:52.217 [data-plane-kafka-request-handler-3] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
…00:17:52.217 [data-plane-kafka-request-handler-3] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
…00:17:52.217 [data-plane-kafka-request-handler-3] INFO state.change.logger -- [Broker id=0] Leader __consumer_offsets-4 with topic id Some(WMeU4zsoQrScNSL1RW_Opg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
™00:17:52.231 [data-plane-kafka-request-handler-3] INFO kafka.log.UnifiedLog$ -- [LogLoader partition=__consumer_offsets-1, dir=C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846] Loading producer state till offset 0 with message format version 2
‹00:17:52.232 [data-plane-kafka-request-handler-3] INFO kafka.log.LogManager -- Created log for partition __consumer_offsets-1 in C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
«00:17:52.232 [data-plane-kafka-request-handler-3] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
…00:17:52.232 [data-plane-kafka-request-handler-3] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
…00:17:52.232 [data-plane-kafka-request-handler-3] INFO state.change.logger -- [Broker id=0] Leader __consumer_offsets-1 with topic id Some(WMeU4zsoQrScNSL1RW_Opg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
™00:17:52.246 [data-plane-kafka-request-handler-3] INFO kafka.log.UnifiedLog$ -- [LogLoader partition=__consumer_offsets-0, dir=C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846] Loading producer state till offset 0 with message format version 2
‹00:17:52.247 [data-plane-kafka-request-handler-3] INFO kafka.log.LogManager -- Created log for partition __consumer_offsets-0 in C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
«00:17:52.247 [data-plane-kafka-request-handler-3] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
…00:17:52.247 [data-plane-kafka-request-handler-3] INFO kafka.cluster.Partition -- [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
…00:17:52.248 [data-plane-kafka-request-handler-3] INFO state.change.logger -- [Broker id=0] Leader __consumer_offsets-0 with topic id Some(WMeU4zsoQrScNSL1RW_Opg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
∂00:17:52.256 [data-plane-kafka-request-handler-3] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
·00:17:52.256 [data-plane-kafka-request-handler-3] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
∂00:17:52.257 [data-plane-kafka-request-handler-3] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
·00:17:52.258 [data-plane-kafka-request-handler-3] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
∂00:17:52.258 [data-plane-kafka-request-handler-3] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
·00:17:52.258 [data-plane-kafka-request-handler-3] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
∂00:17:52.258 [data-plane-kafka-request-handler-3] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
·00:17:52.258 [data-plane-kafka-request-handler-3] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
∂00:17:52.258 [data-plane-kafka-request-handler-3] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
·00:17:52.258 [data-plane-kafka-request-handler-3] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
∂00:17:52.258 [data-plane-kafka-request-handler-3] INFO state.change.logger -- [Broker id=0] Finished LeaderAndIsr request in 86ms correlationId 3 from controller 0 for 5 partitions
Ù00:17:52.259 [data-plane-kafka-request-handler-7] INFO state.change.logger -- [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
ô00:17:52.261 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
ô00:17:52.261 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler.
ô00:17:52.262 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 4 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler.
ô00:17:52.262 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
ô00:17:52.262 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager -- [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
Î00:17:52.356 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Discovered group coordinator localhost:54143 (id: 2147483647 rack: null)
µ00:17:52.360 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] (Re-)joining group
…00:17:52.374 [data-plane-kafka-request-handler-4] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Dynamic member with unknown member id joins group test-group in Empty state. Created a new member id consumer-test-group-1-c99bf8fa-6b5b-4975-bf28-6c9049688502 and request the member to rejoin with this id.
•00:17:52.377 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-1-c99bf8fa-6b5b-4975-bf28-6c9049688502
“00:17:52.378 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
µ00:17:52.378 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] (Re-)joining group
†00:17:52.384 [data-plane-kafka-request-handler-2] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-test-group-1-c99bf8fa-6b5b-4975-bf28-6c9049688502 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
π00:17:52.389 [executor-Rebalance] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Stabilized group test-group generation 1 (__consumer_offsets-2) with 1 members
¿00:17:52.391 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-1-c99bf8fa-6b5b-4975-bf28-6c9049688502', protocol='range'}
º00:17:52.392 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Finished assignment for group at generation 1: {consumer-test-group-1-c99bf8fa-6b5b-4975-bf28-6c9049688502=Assignment(partitions=[audio-packet-topic-0])}
¨00:17:52.399 [data-plane-kafka-request-handler-5] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Assignment received from leader consumer-test-group-1-c99bf8fa-6b5b-4975-bf28-6c9049688502 for group test-group for generation 1. The group has 1 members, 0 of which are static.
æ00:17:52.408 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-1-c99bf8fa-6b5b-4975-bf28-6c9049688502', protocol='range'}
Ò00:17:52.409 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Notifying assignor about the new Assignment(partitions=[audio-packet-topic-0])
Ÿ00:17:52.410 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Adding newly assigned partitions: audio-packet-topic-0
ﬂ00:17:52.418 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Found no committed offset for partition audio-packet-topic-0
Ò00:17:52.428 [Test worker] INFO org.apache.kafka.clients.consumer.internals.SubscriptionState -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Resetting offset for partition audio-packet-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:54143 (id: 0 rack: null)], epoch=0}}.
›00:17:52.475 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Revoke previously assigned partitions audio-packet-topic-0
ﬁ00:17:52.476 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Member consumer-test-group-1-c99bf8fa-6b5b-4975-bf28-6c9049688502 sending LeaveGroup request to coordinator localhost:54143 (id: 2147483647 rack: null) due to the consumer is being closed
ı00:17:52.476 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
Ë00:17:52.476 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-test-group-1, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
˚00:17:52.479 [data-plane-kafka-request-handler-4] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member consumer-test-group-1-c99bf8fa-6b5b-4975-bf28-6c9049688502 on LeaveGroup; client reason: the consumer is being closed)
¡00:17:52.480 [data-plane-kafka-request-handler-4] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Group test-group with generation 2 is now empty (__consumer_offsets-2)
Ó00:17:52.482 [data-plane-kafka-request-handler-4] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-test-group-1-c99bf8fa-6b5b-4975-bf28-6c9049688502, groupInstanceId=None, clientId=consumer-test-group-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group test-group through explicit `LeaveGroup`; client reason: the consumer is being closed
e00:17:52.484 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics scheduler closed
â00:17:52.484 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Closing reporter org.apache.kafka.common.metrics.JmxReporter
e00:17:52.484 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics reporters closed
è00:17:52.485 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- App info kafka.consumer for consumer-test-group-1 unregistered
@Consumed record: key = test-session, value length = 5120 bytes
NFirst 20 bytes: 9A CC 95 4C 6C 9A A6 D6 9E BC 47 F6 11 AB D5 5F E6 DA 3A E4 
 ^00:17:52.486 [Test worker] INFO kafka.server.KafkaServer -- [KafkaServer id=0] shutting down
 °00:17:52.486 [Test worker] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread -- [/config/changes-event-process-thread]: Shutting down
 ¶00:17:52.487 [Test worker] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread -- [/config/changes-event-process-thread]: Shutdown completed
 ¥00:17:52.487 [/config/changes-event-process-thread] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread -- [/config/changes-event-process-thread]: Stopped
 ô00:17:52.487 [Test worker] INFO kafka.network.SocketServer -- [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
  00:17:52.489 [BrokerToControllerChannelManager broker=0 name=forwarding] INFO org.apache.kafka.clients.NetworkClient -- [BrokerToControllerChannelManager broker=0 name=forwarding] Node 0 disconnected.
 ò00:17:52.490 [Test worker] INFO kafka.network.SocketServer -- [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
 á00:17:52.490 [Test worker] INFO kafka.server.KafkaRequestHandlerPool -- [data-plane Kafka Request Handler on Broker 0], shutting down
 é00:17:52.491 [Test worker] INFO kafka.server.KafkaRequestHandlerPool -- [data-plane Kafka Request Handler on Broker 0], shut down completely
 ê00:17:52.492 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-AlterAcls]: Shutting down
 ï00:17:52.493 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-AlterAcls]: Shutdown completed
 õ00:17:52.493 [ExpirationReaper-0-AlterAcls] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-AlterAcls]: Stopped
 [00:17:52.493 [Test worker] INFO kafka.server.KafkaApis -- [KafkaApi-0] Shutdown complete.
 å00:17:52.494 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-topic]: Shutting down
 ì00:17:52.494 [ExpirationReaper-0-topic] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-topic]: Stopped
 ë00:17:52.494 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-topic]: Shutdown completed
 Ü00:17:52.494 [Test worker] INFO kafka.coordinator.transaction.TransactionCoordinator -- [TransactionCoordinator id=0] Shutting down.
 ã00:17:52.495 [Test worker] INFO kafka.coordinator.transaction.TransactionStateManager -- [Transaction State Manager 0]: Shutdown complete
 ò00:17:52.495 [Test worker] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager -- [Transaction Marker Channel Manager 0]: Shutting down
 û00:17:52.495 [TxnMarkerSenderThread-0] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager -- [Transaction Marker Channel Manager 0]: Stopped
 ù00:17:52.495 [Test worker] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager -- [Transaction Marker Channel Manager 0]: Shutdown completed
 ä00:17:52.495 [Test worker] INFO kafka.coordinator.transaction.TransactionCoordinator -- [TransactionCoordinator id=0] Shutdown complete.
 r00:17:52.495 [Test worker] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Shutting down.
 ê00:17:52.496 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Heartbeat]: Shutting down
 ï00:17:52.496 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Heartbeat]: Shutdown completed
 õ00:17:52.496 [ExpirationReaper-0-Heartbeat] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Heartbeat]: Stopped
 ê00:17:52.496 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Rebalance]: Shutting down
 õ00:17:52.496 [ExpirationReaper-0-Rebalance] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Rebalance]: Stopped
 ï00:17:52.496 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Rebalance]: Shutdown completed
 v00:17:52.496 [Test worker] INFO kafka.coordinator.group.GroupCoordinator -- [GroupCoordinator 0]: Shutdown complete.
 h00:17:52.496 [Test worker] INFO kafka.server.ReplicaManager -- [ReplicaManager broker=0] Shutting down
 {00:17:52.497 [Test worker] INFO kafka.server.ReplicaManager$LogDirFailureHandler -- [LogDirFailureHandler]: Shutting down
 Ä00:17:52.497 [Test worker] INFO kafka.server.ReplicaManager$LogDirFailureHandler -- [LogDirFailureHandler]: Shutdown completed
 ~00:17:52.497 [LogDirFailureHandler] INFO kafka.server.ReplicaManager$LogDirFailureHandler -- [LogDirFailureHandler]: Stopped
 y00:17:52.497 [Test worker] INFO kafka.server.ReplicaFetcherManager -- [ReplicaFetcherManager on broker 0] shutting down
 ~00:17:52.498 [Test worker] INFO kafka.server.ReplicaFetcherManager -- [ReplicaFetcherManager on broker 0] shutdown completed
 É00:17:52.498 [Test worker] INFO kafka.server.ReplicaAlterLogDirsManager -- [ReplicaAlterLogDirsManager on broker 0] shutting down
 à00:17:52.498 [Test worker] INFO kafka.server.ReplicaAlterLogDirsManager -- [ReplicaAlterLogDirsManager on broker 0] shutdown completed
 å00:17:52.498 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Fetch]: Shutting down
 ë00:17:52.498 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Fetch]: Shutdown completed
 ì00:17:52.498 [ExpirationReaper-0-Fetch] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Fetch]: Stopped
 é00:17:52.498 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Produce]: Shutting down
 ì00:17:52.499 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Produce]: Shutdown completed
 ó00:17:52.499 [ExpirationReaper-0-Produce] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-Produce]: Stopped
 î00:17:52.499 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-DeleteRecords]: Shutting down
 ô00:17:52.499 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-DeleteRecords]: Shutdown completed
 £00:17:52.499 [ExpirationReaper-0-DeleteRecords] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-DeleteRecords]: Stopped
 í00:17:52.499 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-ElectLeader]: Shutting down
 ü00:17:52.499 [ExpirationReaper-0-ElectLeader] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-ElectLeader]: Stopped
 ó00:17:52.499 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper -- [ExpirationReaper-0-ElectLeader]: Shutdown completed
 o00:17:52.505 [Test worker] INFO kafka.server.ReplicaManager -- [ReplicaManager broker=0] Shut down completely
 †00:17:52.505 [Test worker] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
 Ã00:17:52.506 [BrokerToControllerChannelManager broker=0 name=alterPartition] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
 •00:17:52.506 [Test worker] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
 ó00:17:52.506 [Test worker] INFO kafka.server.BrokerToControllerChannelManagerImpl -- Broker to controller channel manager for alterPartition shutdown
 ú00:17:52.506 [Test worker] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
 ƒ00:17:52.507 [BrokerToControllerChannelManager broker=0 name=forwarding] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
 °00:17:52.507 [Test worker] INFO kafka.server.BrokerToControllerRequestThread -- [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
 ì00:17:52.507 [Test worker] INFO kafka.server.BrokerToControllerChannelManagerImpl -- Broker to controller channel manager for forwarding shutdown
 H00:17:52.507 [Test worker] INFO kafka.log.LogManager -- Shutting down.
 X00:17:52.507 [Test worker] INFO kafka.log.LogCleaner -- Shutting down the log cleaner.
 e00:17:52.508 [Test worker] INFO kafka.log.LogCleaner -- [kafka-log-cleaner-thread-0]: Shutting down
 j00:17:52.509 [Test worker] INFO kafka.log.LogCleaner -- [kafka-log-cleaner-thread-0]: Shutdown completed
 n00:17:52.509 [kafka-log-cleaner-thread-0] INFO kafka.log.LogCleaner -- [kafka-log-cleaner-thread-0]: Stopped
 †00:17:52.555 [log-closing-C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846] INFO kafka.log.ProducerStateManager -- [ProducerStateManager partition=audio-packet-topic-0] Wrote producer snapshot at offset 1 with 1 producer ids in 6 ms.
 †00:17:52.567 [log-closing-C:\Users\user\AppData\Local\Temp\spring.kafka.99794a4f-d7af-4653-ace4-a620fb72b4199950441495134487846] INFO kafka.log.ProducerStateManager -- [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 3 with 0 producer ids in 5 ms.
 L00:17:52.585 [Test worker] INFO kafka.log.LogManager -- Shutdown complete.
 ó00:17:52.586 [Test worker] INFO kafka.controller.ControllerEventManager$ControllerEventThread -- [ControllerEventThread controllerId=0] Shutting down
 ù00:17:52.586 [controller-event-thread] INFO kafka.controller.ControllerEventManager$ControllerEventThread -- [ControllerEventThread controllerId=0] Stopped
 ú00:17:52.586 [Test worker] INFO kafka.controller.ControllerEventManager$ControllerEventThread -- [ControllerEventThread controllerId=0] Shutdown completed
 î00:17:52.587 [Test worker] INFO kafka.controller.ZkPartitionStateMachine -- [PartitionStateMachine controllerId=0] Stopped partition state machine
 é00:17:52.587 [Test worker] INFO kafka.controller.ZkReplicaStateMachine -- [ReplicaStateMachine controllerId=0] Stopped replica state machine
 x00:17:52.588 [Test worker] INFO kafka.controller.RequestSendThread -- [RequestSendThread controllerId=0] Shutting down
 }00:17:52.588 [Test worker] INFO kafka.controller.RequestSendThread -- [RequestSendThread controllerId=0] Shutdown completed
 ã00:17:52.588 [Controller-0-to-broker-0-send-thread] INFO kafka.controller.RequestSendThread -- [RequestSendThread controllerId=0] Stopped
 `00:17:52.588 [Test worker] INFO kafka.controller.KafkaController -- [Controller id=0] Resigned
 ®00:17:52.589 [Test worker] INFO kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread -- [feature-zk-node-event-process-thread]: Shutting down
 ≠00:17:52.589 [Test worker] INFO kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread -- [feature-zk-node-event-process-thread]: Shutdown completed
 ª00:17:52.589 [feature-zk-node-event-process-thread] INFO kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread -- [feature-zk-node-event-process-thread]: Stopped
 l00:17:52.590 [Test worker] INFO kafka.zookeeper.ZooKeeperClient -- [ZooKeeperClient Kafka server] Closing.
 e00:17:52.693 [Test worker] INFO org.apache.zookeeper.ZooKeeper -- Session: 0x100040683320000 closed
 Ö00:17:52.694 [Test worker-EventThread] INFO org.apache.zookeeper.ClientCnxn -- EventThread shut down for session: 0x100040683320000
 k00:17:52.694 [Test worker] INFO kafka.zookeeper.ZooKeeperClient -- [ZooKeeperClient Kafka server] Closed.
 â00:17:52.695 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Fetch]: Shutting down
 î00:17:52.696 [ThrottledChannelReaper-Fetch] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Fetch]: Stopped
 é00:17:52.696 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Fetch]: Shutdown completed
 ã00:17:52.696 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Produce]: Shutting down
 ò00:17:52.696 [ThrottledChannelReaper-Produce] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Produce]: Stopped
 ê00:17:52.696 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Produce]: Shutdown completed
 ã00:17:52.696 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Request]: Shutting down
 ò00:17:52.696 [ThrottledChannelReaper-Request] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Request]: Stopped
 ê00:17:52.696 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-Request]: Shutdown completed
 ñ00:17:52.696 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-ControllerMutation]: Shutting down
 Æ00:17:52.696 [ThrottledChannelReaper-ControllerMutation] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-ControllerMutation]: Stopped
 õ00:17:52.696 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper -- [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
 ã00:17:52.697 [Test worker] INFO kafka.network.SocketServer -- [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
 Ç00:17:52.712 [Test worker] INFO kafka.network.SocketServer -- [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
 e00:17:52.712 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics scheduler closed
 â00:17:52.712 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Closing reporter org.apache.kafka.common.metrics.JmxReporter
 e00:17:52.712 [Test worker] INFO org.apache.kafka.common.metrics.Metrics -- Metrics reporters closed
 `00:17:52.713 [Test worker] INFO kafka.server.BrokerTopicStats -- Broker and topic stats closed
 y00:17:52.714 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- App info kafka.server for 0 unregistered
 d00:17:52.714 [Test worker] INFO kafka.server.KafkaServer -- [KafkaServer id=0] shut down completed
 Å00:17:52.734 [ConnnectionExpirer] INFO org.apache.zookeeper.server.NIOServerCnxnFactory -- ConnnectionExpirerThread interrupted
 ò00:17:52.735 [NIOServerCxnFactory.AcceptThread:/127.0.0.1:0] INFO org.apache.zookeeper.server.NIOServerCnxnFactory -- accept thread exitted run method
 ë00:17:52.735 [NIOServerCxnFactory.SelectorThread-1] INFO org.apache.zookeeper.server.NIOServerCnxnFactory -- selector thread exitted run method
 ë00:17:52.736 [NIOServerCxnFactory.SelectorThread-2] INFO org.apache.zookeeper.server.NIOServerCnxnFactory -- selector thread exitted run method
 ë00:17:52.736 [NIOServerCxnFactory.SelectorThread-0] INFO org.apache.zookeeper.server.NIOServerCnxnFactory -- selector thread exitted run method
 ^00:17:52.736 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer -- shutting down
 _00:17:52.736 [Test worker] INFO org.apache.zookeeper.server.RequestThrottler -- Shutting down
 w00:17:52.736 [RequestThrottler] INFO org.apache.zookeeper.server.RequestThrottler -- Draining request throttler queue
 Ñ00:17:52.736 [RequestThrottler] INFO org.apache.zookeeper.server.RequestThrottler -- RequestThrottler shutdown. Dropped 0 requests
 a00:17:52.736 [Test worker] INFO org.apache.zookeeper.server.SessionTrackerImpl -- Shutting down
 c00:17:52.736 [Test worker] INFO org.apache.zookeeper.server.PrepRequestProcessor -- Shutting down
 c00:17:52.736 [Test worker] INFO org.apache.zookeeper.server.SyncRequestProcessor -- Shutting down
 ç00:17:52.736 [ProcessThread(sid:0 cport:54139):] INFO org.apache.zookeeper.server.PrepRequestProcessor -- PrepRequestProcessor exited loop!
 s00:17:52.736 [SyncThread:0] INFO org.apache.zookeeper.server.SyncRequestProcessor -- SyncRequestProcessor exited!
 }00:17:52.736 [Test worker] INFO org.apache.zookeeper.server.FinalRequestProcessor -- shutdown of request processor complete
